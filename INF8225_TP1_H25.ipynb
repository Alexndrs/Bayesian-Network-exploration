{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAHWMYJv4xuc"
      },
      "source": [
        "# INF8225 TP1 H25 (v2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV-6EDgXO-S9"
      },
      "source": [
        "Alexandre - Dréan / 2408681 ########\n",
        "\n",
        "Partie 3 réalisée: [seul(e)]\n",
        "ou avec\n",
        "[Prénom - NOM -\n",
        "Matricule ########]\n",
        "\n",
        "Date limite :\n",
        "\n",
        "20h30 le 6 février 2025 (Partie 1 et 2)\n",
        "\n",
        "20h30 le 20 février 2025 (Partie 3)\n",
        "\n",
        "Remettez votre fichier Colab sur Moodle en 2 formats: **.pdf** ET **.ipynb**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo2CPniBeytl"
      },
      "source": [
        "**Comment utiliser**:\n",
        "\n",
        "Il faut copier ce notebook dans vos dossiers pour avoir une version que vous pouvez modifier, voici deux façons de le faire:\n",
        "* File / Save a copy in Drive ...\n",
        "* File / Download .ipynb\n",
        "\n",
        "**Pour utiliser un GPU**\n",
        "\n",
        "Runtime / Change Runtime Type / Hardware Accelerator / GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCGh-NNm47Tk"
      },
      "source": [
        "# Partie 1 (16 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7tkIgu75Ccd"
      },
      "source": [
        "## Objectif\n",
        "L’objectif de la Partie 1 du travail pratique est de permettre à l’étudiant de se familiariser avec les réseaux Bayésiens et la librairie Numpy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iongVT7XRegv"
      },
      "source": [
        "## Problème\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considérons le réseau Bayésien ci-dessous.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1QCJSfYGLJVg2-0_BO8BEHCnMEDsHSR6k\" alt=\"bayes_net\" width=\"600\"/>\n",
        "\n",
        "Ceci représente un modèle simple pour les notes à un examen (G) et sa relation avec les étudiants qui se préparent aux examens et font correctement le travail pour les devoirs (S), les étudiants qui ont des difficultés dans la vie juste avant l'examen final (D), les étudiants qui réussissent bien à un entretien technique pour un emploi axé sur le sujet du cours (R), et des étudiants qui se retrouvent sur une sorte de palmarès de leur programme (L)."
      ],
      "metadata": {
        "id": "tdKetLE0hVev"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twz4slZ9DY6n"
      },
      "source": [
        "## Trucs et astuces\n",
        "Nous utiliserons des vecteurs multidimensionnels `5d-arrays` dont les `axes` représentent:\n",
        "```\n",
        "axe 0 : Se préparer (S)\n",
        "axe 1 : Difficultés avant l'exam (D)\n",
        "axe 2 : Réussir l'entretien technique (R)\n",
        "axe 3 : Note dans le cours (Grade) (G)\n",
        "axe 4 : Liste d'honneur (L)\n",
        "```\n",
        "\n",
        "Chaque `axe` serait de dimension `2` ou `3`:\n",
        "```\n",
        "Exemple pour S:\n",
        "0 : s0\n",
        "1 : s1\n",
        "\n",
        "Exemple pour G:\n",
        "0 : g0\n",
        "1 : g1\n",
        "2 : g2\n",
        "```\n",
        "Quelques point à garder en tête:\n",
        "- Utiliser la jointe comme point de départ pour vos calculs (ne pas développer tous les termes à la main).\n",
        "- Attention à l'effet du do-operator sur le graphe.\n",
        "- L'argument \"keepdims=True\" de \"np.sum()\" vous permet conserver les mêmes indices.\n",
        "- Pour un rappel sur les probabilités conditionelles, voir: https://www.probabilitycourse.com/chapter1/1_4_0_conditional_probability.php"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUjUNqVcTEXP"
      },
      "source": [
        "## 1. Complétez les tables de probabilités ci-dessous"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-rxnQmCCCPa",
        "outputId": "d77b94fe-c141-44ec-8484-b2e0446bf67a"
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=5)\n",
        "\n",
        "# Les tableaux sont bâtis avec les dimensions (S, D, R, G, L)\n",
        "# et chaque dimension avec les probablités associées aux 2 ou 3 valeurs possibles ({0, 1} ou {0, 1, 2})\n",
        "\n",
        "Pr_S = np.array([0.2, 0.8]).reshape(2, 1, 1, 1, 1) # Donné en exemple\n",
        "Pr_D = np.array([0.9, 0.1]).reshape(1, 2, 1, 1, 1) # TODO\n",
        "Pr_R_given_S = np.array([\n",
        "    [0.9, 0.1],\n",
        "    [0.2, 0.8]\n",
        "]).reshape(2, 1, 2, 1, 1) # TODO\n",
        "Pr_G_given_SD = np.array([\n",
        "    [[0.5, 0.3, 0.2],\n",
        "     [0.9, 0.08, 0.02]],\n",
        "\n",
        "    [[0.1, 0.2, 0.7],\n",
        "     [0.3, 0.4, 0.3]]\n",
        "]).reshape(2, 2, 1, 3, 1) # TODO\n",
        "Pr_L_given_G = np.array([\n",
        "    [0.9, 0.1],\n",
        "    [0.6, 0.4],\n",
        "    [0.01, 0.99]\n",
        "]).reshape(1, 1, 1, 3, 2) # TODO\n",
        "\n",
        "print (f\"Pr(S)=\\n{np.squeeze(Pr_S)}\\n\")\n",
        "print (f\"Pr(D)=\\n{np.squeeze(Pr_D)}\\n\")\n",
        "print (f\"Pr(R|S)=\\n{np.squeeze(Pr_R_given_S)}\\n\")\n",
        "print (f\"Pr(G|S,D)=\\n{np.squeeze(Pr_G_given_SD)}\\n\")\n",
        "print (f\"Pr(L|G)=\\n{np.squeeze(Pr_L_given_G)}\\n\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(S)=\n",
            "[0.2 0.8]\n",
            "\n",
            "Pr(D)=\n",
            "[0.9 0.1]\n",
            "\n",
            "Pr(R|S)=\n",
            "[[0.9 0.1]\n",
            " [0.2 0.8]]\n",
            "\n",
            "Pr(G|S,D)=\n",
            "[[[0.5  0.3  0.2 ]\n",
            "  [0.9  0.08 0.02]]\n",
            "\n",
            " [[0.1  0.2  0.7 ]\n",
            "  [0.3  0.4  0.3 ]]]\n",
            "\n",
            "Pr(L|G)=\n",
            "[[0.9  0.1 ]\n",
            " [0.6  0.4 ]\n",
            " [0.01 0.99]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHD6DX-nS6Qt"
      },
      "source": [
        "## 2. À l'aide de ces tables de probabilité conditionnelles, calculez les requêtes ci-dessous. Dans les cas où l'on compare un calcul non interventionnel à un calcul interventionnel, commentez sur l'interprétation physique des deux situations et les résultats obtenus à partir de vos modèles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-vXI0O279sX"
      },
      "source": [
        "a) $Pr(G) = [P (G = g^0), P (G = g^1), P (G = g^2)]$\n",
        "\n",
        "$P(G) = \\sum_{s,d} P(S=s).P(D=d).P(G|S=s,D=d)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXWtZDsv791d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed7058e4-7846-4732-bd66-bf6b41753f4e"
      },
      "source": [
        "Pr_G = np.sum(Pr_S * Pr_D * Pr_G_given_SD, axis=(0,1), keepdims=True)\n",
        "\n",
        "answer_a = Pr_G.squeeze() # TODO\n",
        "print(f\"Pr(G)={answer_a}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(G)=[0.204  0.2316 0.5644]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7fla36P79_G"
      },
      "source": [
        "b) $Pr(G|R = r^1)$\n",
        "$P(G|R=r1) = \\frac{P(G,R=r1)}{P(R=r1)} = \\frac{\\sum_{s,d} P(S=s).P(D=d).P(R=r1|S=s).P(G|S=s,D=d)}{\\sum_s P(S=s).P(R=r1|S=s)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Jp2AGLa7-H_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "894c0434-4e4e-41ef-f751-3757b184c373"
      },
      "source": [
        "Pr_GR = np.sum(Pr_S * Pr_D * Pr_R_given_S * Pr_G_given_SD, axis=(0,1), keepdims=True)\n",
        "Pr_R = np.sum(Pr_S * Pr_R_given_S, axis=0, keepdims=True)\n",
        "Pr_G_given_R = Pr_GR / Pr_R\n",
        "\n",
        "answer_b = Pr_G_given_R[:,:,1,:,:].squeeze() # TODO\n",
        "print(f\"Pr(G|R=r1)={answer_b}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(G|R=r1)=[0.13273 0.22176 0.64552]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8mt03aX7-WC"
      },
      "source": [
        "c)  $Pr(G|R = r^0)$\n",
        "\n",
        "pareil qu'au dessus en remplaçant $r^1$ par $r^0$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCxSweb67-dx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "103a8390-102a-4534-9a2c-c63e04202334"
      },
      "source": [
        "answer_c = Pr_G_given_R[:,:,0,:,:].squeeze() # TODO\n",
        "print(f\"Pr(G|R=r0)={answer_c}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(G|R=r0)=[0.34235 0.25071 0.40694]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSK8ulij7-m0"
      },
      "source": [
        "d) $Pr(G|R=r^1, S=s^0)$\n",
        "\n",
        "$P(G|R=r1,S=s0) =\\frac{ P(G,R=r1,S=s0)}{P(R=r1,S=s0)} = \\frac{\\sum_d P(S=s0).P(D=d).P(R=r1|S=s0).P(G|S=s0,D=d)}{P(S=s0).P(R=r1|S=s0)} $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cliFsd8f7-vC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd2f46ef-4e82-48a6-e280-a4b0fd50d78e"
      },
      "source": [
        "Pr_GRS = np.sum(Pr_S * Pr_D * Pr_R_given_S * Pr_G_given_SD, axis=1, keepdims=True)\n",
        "Pr_RS = Pr_S * Pr_R_given_S\n",
        "Pr_G_given_RS = Pr_GRS / Pr_RS\n",
        "\n",
        "answer_d = Pr_G_given_RS[0,:,1,:,:].squeeze() # TODO\n",
        "print(f\"Pr(G|R=r1, S=s0)={answer_d}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(G|R=r1, S=s0)=[0.54  0.278 0.182]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zffAAOW67-5I"
      },
      "source": [
        "e) $Pr(G|R=r^0, S=s^0)$\n",
        "\n",
        "remarque : on va obtenir pareil que pour la question précédente car sous $S$ fixé on a $G$ indépendant de $R$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zyt7TeB7_CD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6818bd-b08c-40bf-d838-f73e62c77c65"
      },
      "source": [
        "answer_e = Pr_G_given_RS[0,:,0,:,:].squeeze() # TODO\n",
        "print(f\"Pr(G|R=r0, S=s0)={answer_e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(G|R=r0, S=s0)=[0.54  0.278 0.182]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeIkZjn47_LZ"
      },
      "source": [
        "f) $Pr(R|D=d^1)$\n",
        "\n",
        "On peut directement dire que $P(R|D=d1) = P(R)$ car R est indépendant de D, on fait quand même le calcule pour le démontrer\n",
        "\n",
        "$P(R|D=d1) = \\sum_s P(R,S=s|D=d1) = sum_s P(R|S=s,D=d1).P(S=s|D=d1) = \\sum_s P(R|S=s).P(S=s) = P(R)$ (car R est indépendant de D selon S fixé et S est indépendant de D)\n",
        "\n",
        "$P(R|D=d1) = P(R)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yscy5bf27_Sq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f29253e-512f-45d0-846a-eb1b517de9fe"
      },
      "source": [
        "\n",
        "\n",
        "answer_f = Pr_R.squeeze() # TODO\n",
        "print(f\"Pr(R|D=d1)={answer_f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|D=d1)=[0.34 0.66]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbV8cFjU8TxQ"
      },
      "source": [
        "g) $Pr(R|D=d^0)$\n",
        "\n",
        "$Pr(R|D=d^0) = Pr(R)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jBgoNDz8T6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c155a56-3168-470c-d65a-4d0a85241e7e"
      },
      "source": [
        "answer_g = Pr_R.squeeze() # TODO\n",
        "print(f\"Pr(R|D=d0)={answer_g}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|D=d0)=[0.34 0.66]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05xm-VaW8UQh"
      },
      "source": [
        "h) $Pr(R|D=d^1, G=g^2)$\n",
        "\n",
        "$P(R|D=d1,G=g2) = \\frac{P(R,D=d1,G=g2)}{P(D=d1,G=g2)} = \\frac{\\sum_s P(S=s).P(D=d1).P(R|S=s).P(G=g2|S=s,D=d1)}{\\sum_s P(S=s).P(D=d1).P(G=g2|S=s,D=d1)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shjD8GIL8UZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4899b9e-928f-40c9-e284-4c6dceb9b8a8"
      },
      "source": [
        "Pr_RDG = np.sum(Pr_S * Pr_D * Pr_R_given_S * Pr_G_given_SD, axis=0, keepdims=True)\n",
        "Pr_DG = np.sum(Pr_S * Pr_D * Pr_G_given_SD, axis=0, keepdims=True)\n",
        "Pr_R_given_DG = Pr_RDG / Pr_DG\n",
        "answer_h = Pr_R_given_DG[:,1,:,2,:].squeeze() # TODO\n",
        "print(f\"Pr(R|D=d1, G=g2)={answer_h}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|D=d1, G=g2)=[0.21148 0.78852]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i2ahKAj8Umu"
      },
      "source": [
        "i) $Pr(R|D=d^0, G=g^2)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nLKd4c18UuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07b1514-b07c-4843-8343-cdf6522614b2"
      },
      "source": [
        "answer_i = Pr_R_given_DG[:,0,:,2,:].squeeze() # TODO\n",
        "print(f\"Pr(R|D=d0, G=g2)={answer_i}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|D=d0, G=g2)=[0.24667 0.75333]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUc0EpO18eA-"
      },
      "source": [
        "j) $Pr(R|D=d^1, L=l^1)$\n",
        "\n",
        "$P(R|D=d1,L=l1) = \\frac{P(R,D=d1,L=l1)}{P(D=d1,L=l1)} = \\frac{\\sum_{s,g} P(S=s).P(D=d1).P(R|S=s).P(G=g|S=s,D=d1).P(L=l1|G=g)}{\\sum_{s,g} P(S=s).P(D=d1).P(G=g|S=s,D=d1).P(L=l1|G=g)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgDLu0nJ8eM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a5db78-7ac5-4470-e477-df8e814b4766"
      },
      "source": [
        "Pr_RDL = np.sum(Pr_S * Pr_D * Pr_R_given_S * Pr_G_given_SD * Pr_L_given_G, axis=(0,3), keepdims=True)\n",
        "Pr_DL = np.sum(Pr_S * Pr_D * Pr_G_given_SD * Pr_L_given_G, axis=(0,3), keepdims=True)\n",
        "Pr_R_given_DL = Pr_RDL / Pr_DL\n",
        "\n",
        "answer_j = Pr_R_given_DL[:,1,:,:,1].squeeze() # TODO\n",
        "print(f\"Pr(R|D=d1, L=l1)={answer_j}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|D=d1, L=l1)=[0.2475 0.7525]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "k) $Pr(R|D=d^0, L=l^1)$\n",
        "\n",
        "On remplace $d^1$ par $d^0$"
      ],
      "metadata": {
        "id": "G2rCcDgyuo5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_k = Pr_R_given_DL[:,0,:,:,1].squeeze() # TODO\n",
        "print(f\"Pr(R|D=d1, L=l1)={answer_k}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpt2RPQqvHbj",
        "outputId": "39778da6-2599-44ae-ed8b-c3b0eb8e8fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|D=d1, L=l1)=[0.2736 0.7264]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "l) $Pr(R|do(G=g^2))$\n",
        "\n",
        "$P(R|do(G=g2)) = P(R)$ car si nous forçons la valeur de $G$ celle ci n'est plus causée par $S$ et donc est $G$ est indépendante de $R$"
      ],
      "metadata": {
        "id": "eiHUsWItvL2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_l = Pr_R.squeeze() # TODO\n",
        "print(f\"Pr(R|do(G=g2))={answer_l}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag5OS3B_vT35",
        "outputId": "0b458670-e97a-4154-ee6b-ad7663f3546e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|do(G=g2))=[0.34 0.66]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "m) $Pr(R|G=g^2)$\n",
        "\n",
        "$P(R|G=g2) = \\sum_s P(R,S=s|G=g2) = \\sum_s P(S=s|G=g2)P(R|S=s,G=g2) = \\sum_s P(S=s|G=g2)P(R|S=s)$\n",
        "Et\n",
        "$P(S=s|G=g2) = \\frac{P(G=g2|S=s)P(S=s)}{P(G=g2)} = \\frac{\\sum_d P(G=g2|S=s,D=d)P(D=d)P(S=s)}{P(G=g2)}$"
      ],
      "metadata": {
        "id": "Dm1JoSs51P6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Pr_S_given_G = np.sum(Pr_G_given_SD * Pr_D * Pr_S, axis=1, keepdims=True) / Pr_G\n",
        "Pr_R_given_G = np.sum(Pr_S_given_G * Pr_R_given_S, axis=0, keepdims=True)\n",
        "\n",
        "answer_m = Pr_R_given_G[:,:,:,2,:].squeeze() # TODO\n",
        "print(f\"Pr(R|G=g2)={answer_m}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lT5Bhwm1Vca",
        "outputId": "d345379d-d610-4271-a363-4df84a015597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|G=g2)=[0.24515 0.75485]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "n) $Pr(R)$\n",
        "déjà calculer à la question b"
      ],
      "metadata": {
        "id": "2yAntka31ZDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_n = Pr_R.squeeze() # TODO\n",
        "print(f\"Pr(R={answer_n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3156HkiD1mNe",
        "outputId": "b79aa02d-7408-4167-8110-d72d9cca6c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R=[0.34 0.66]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "o) $Pr(G|do(L=l^1))$\n",
        "\n",
        "Le fait de forcer $L$ à $1$ ne change pas les probabilités de $G$:\n",
        "\n",
        "$P(G|do(L=l1)) = \\sum_{s,d} P(G,S=s,D=d|do(L=l1)) = \\sum_{s,d} P(G,S=s,D=d) = \\sum_{s,d} P(G|S=s,D=d)P(S=s)P(D=d) = P(G) $"
      ],
      "metadata": {
        "id": "wR0NIlpE1dni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_o = Pr_G.squeeze() # TODO\n",
        "print(f\"Pr(G|do(L=l1))={answer_o}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_SfC2CJ1bb7",
        "outputId": "e0ae3c92-b3eb-4a75-fff7-be5660914d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(G|do(L=l1))=[0.204  0.2316 0.5644]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "p) $Pr(G=1|L=l^1)$\n",
        "\n",
        "$P(G=g1|L=l1) = \\frac{P(L=l1|G=g1)P(G=g1)}{P(L=l1)} = \\frac{P(L=l1|G=g1)P(G=g1)}{\\sum_{g} P(L=l1|G=g).P(G=g)}$"
      ],
      "metadata": {
        "id": "Ac48SDKS1x8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Pr_GL = Pr_L_given_G * Pr_G\n",
        "Pr_L = np.sum(Pr_GL, axis=3, keepdims=True)\n",
        "Pr_G_given_L = Pr_GL / Pr_L\n",
        "\n",
        "answer_p = Pr_G_given_L[:,:,:,1,1].squeeze() # TODO\n",
        "print(f\"Pr(G=1|L=l1)={answer_p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dNsTqjJ11P3",
        "outputId": "5dbe9b45-d04a-41cc-eec5-4f9288153026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(G=1|L=l1)=0.13789900505510602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqfqhDoL5CfA"
      },
      "source": [
        "# Partie 2 (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjIVlyRq5CjA"
      },
      "source": [
        "## Objectif\n",
        "\n",
        "L’objectif de la partie 2 du travail pratique est de permettre à l’étudiant de se familiariser avec l’apprentissage automatique via la régression logistique. Nous allons donc résoudre un problème de classification d'images en utilisant l’approche de descente du gradient (gradient descent) pour optimiser la log-vraisemblance négative (negative log-likelihood) comme fonction de perte.\n",
        "\n",
        "L'algorithme à implémenter est une variation de descente de gradient qui s’appelle l’algorithme de descente de gradient stochastique par mini-ensemble (mini-batch stochastic gradient descent).  Votre objectif est d’écrire un programme en Python pour optimiser les paramètres d’un modèle étant donné un ensemble de données d’apprentissage, en utilisant un ensemble de validation pour déterminer quand arrêter l'optimisation, et finalement de montrer la performance sur l’ensemble du test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFxYYRQJ5Cnb"
      },
      "source": [
        "## Théorie: la régression logistique et le calcul du gradient\n",
        "\n",
        "\n",
        "Il est possible d’encoder l’information concernant l’étiquetage avec des vecteurs multinomiaux (one-hot vectors), c.-à-d. un vecteur de zéros avec un seul 1 pour indiquer quand la classe $C=k$ dans la dimension $k$. Par exemple, le vecteur $\\mathbf{y}=[0, 1, 0, \\cdots, 0]^T$ représente la deuxième classe. Les caractéristiques (features) sont données par des vecteurs $\\mathbf{x}_i \\in \\mathbb{R}^{D}$. En définissant les paramètres de notre modèle comme : $\\mathbf{W}=[\\mathbf{w}_1, \\cdots, \\mathbf{w}_K]^T$ et $\\mathbf{b}=[b_1, b_2, \\cdots  b_K]^T$ et la fonction softmax comme fonction de sortie, on peut exprimer notre modèle sous la forme :\n",
        "\\begin{eqnarray}\n",
        "    p(\\mathbf{y}|\\mathbf{x})\n",
        "    &=& \\frac{\\exp(\\mathbf{y}^T \\mathbf{W} \\mathbf{x} + \\mathbf{y}^T \\mathbf{b})}{\\sum_{\\mathbf{y}_k \\in \\mathscr{Y}} \\exp(\\mathbf{y}_k^T \\mathbf{W} \\mathbf{x} + \\mathbf{y}_k^T \\mathbf{b})}\n",
        "\\end{eqnarray}\n",
        "L'ensemble de données consiste de $n$ paires (label, input) de la forme $\\mathscr{D}:=(\\mathbf{\\tilde{y}}_i, \\mathbf{\\tilde{x}}_i)_{i=1}^n$, où nous utilisons l'astuce de redéfinir $\\mathbf{\\tilde{x}}_i = [\\mathbf{\\tilde{x}}_i^T 1]^T$ et nous redéfinissions la matrice de paramètres $\\boldsymbol{\\theta} \\in \\mathbb{R}^{K\\times(D+1)}$ (voir des notes de cours pour la relation entre $\\boldsymbol{\\theta}$ et $\\mathbf{W}$). Notre fonction de perte, la log-vraisemblance négative des données selon notre modèle est définie comme:\n",
        "\\begin{equation}\n",
        "    \\mathscr{L}\\big( \\boldsymbol{\\theta}, \\mathscr{D} \\big) := -\\log \\prod_{i=1}^N P(\\mathbf{\\tilde{y}}_i|\\mathbf{\\tilde{x}}_i; \\boldsymbol{\\theta})\n",
        "\\end{equation}\n",
        "Pour cette partie du TP, nous avons calculé pour vous le gradient de la fonction de perte par rapport par rapport aux paramètres du modèle:\n",
        "\\begin{eqnarray}\n",
        "    \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\mathscr{L}\\big( \\boldsymbol{\\theta}, \\mathscr{D} \\big)\n",
        "    &=& -\\sum_{i=1}^N \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\Bigg\\{\\log \\Bigg(\\frac{\\exp(\\mathbf{\\tilde{y}}_i^T \\boldsymbol{\\theta} \\mathbf{\\tilde{x}}_i)}{\\sum_{\\mathbf{y}_k \\in \\mathscr{Y}} \\exp(\\mathbf{y}_k^T \\boldsymbol{\\theta} \\mathbf{\\tilde{x}}_i)} \\Bigg) \\Bigg\\} \\\\\n",
        "    &=& -\\sum_{i=1}^N \\left(\\mathbf{\\tilde{y}}_i \\mathbf{\\tilde{x}}^T_i- \\sum_{\\mathbf{y}_k \\in \\mathscr{Y}} P(\\mathbf{y}_k|\\mathbf{\\tilde{x}}_i,\\boldsymbol{\\theta}) \\mathbf{y}_k \\mathbf{\\tilde{x}}^T_i \\right) \\\\\n",
        "    &=& \\sum_{i=1}^N \\mathbf{\\hat{p}}_i \\mathbf{\\tilde{x}}^T_i - \\sum_{i=1}^N \\mathbf{\\tilde{y}}_i \\mathbf{\\tilde{x}}^T_i\n",
        "\\end{eqnarray}\n",
        "où $\\mathbf{\\hat{p}}_i$ est un vecteur de probabilités produit par le modèle pour l'exemple $\\mathbf{\\tilde{x}}_i$ et $\\mathbf{\\tilde{y}}_i$ est le vrai *label* pour ce même exemple.\n",
        "\n",
        "Finalement, il reste à discuter de l'évaluation du modèle. Pour la tâche d'intérêt, qui est une instance du problème de classification, il existe plusieurs métriques pour mesurer les performances du modèle la précision de classification, l'erreur de classification, le taux de faux/vrai positifs/négatifs, etc. Habituellement dans le contexte de l'apprentissage automatique, la précision est la plus commune.\n",
        "\n",
        "La précision est définie comme le rapport du nombre d'échantillons bien classés sur le nombre total d'échantillons à classer:\n",
        "$$\n",
        "\\tau_{acc} := \\frac{|\\mathscr{C}|}{|\\mathscr{D}|}\n",
        "$$\n",
        "où l'ensemble des échantillons bien classés $\\mathscr{C}$ est:\n",
        "$$\n",
        "\\mathscr{C} := \\lbrace (\\mathbf{x}, \\mathbf{y}) \\in \\mathscr{D} \\, | \\, \\underset{k}{\\arg\\max} \\, \\, P(\\cdot|\\mathbf{\\tilde{x}}_i; \\boldsymbol{\\theta})_k = \\underset{k}{\\arg\\max} \\, \\, \\tilde{y}_{i,k} \\rbrace\n",
        "$$\n",
        "En mots, il s'agit du sous-ensemble d'échantillons pour lesquels la classe la plus probable selon notre modèle correspond à la vraie classe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffr5uSLRzkkY"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3wjjnIDGHZj"
      },
      "source": [
        "## Description des tâches\n",
        "\n",
        "#### 1. Code à compléter\n",
        "\n",
        "On vous demande de compléter l'extrait de code ci-dessous pour résoudre ce problème. Vous devez utiliser la librairie PyTorch cette partie du TP: https://pytorch.org/docs/stable/index.html. Mettez à jour les paramètres de votre modèle avec la descente par *mini-batch*. Exécutez des expériences avec trois différents ensembles: un ensemble d’apprentissages avec 90\\% des exemples (choisis au hasard), un ensemble de validation avec 10\\%. Utilisez uniquement l'ensemble de test pour obtenir votre meilleur résultat une fois que vous pensez avoir obtenu votre meilleure stratégie pour entraîner le modèle.\n",
        "\n",
        "#### 2. Rapport à rédiger\n",
        "\n",
        "Présentez vos résultats dans un rapport. Ce rapport devrait inclure:\n",
        "\n",
        "- **Recherche d'hyperparamètres:** Faites une recherche d'hyperparamètres pour différents taux d'apprentissage, e.g. 0.1, 0.01, 0.001, et différentes tailles de mini-batch, e.g. 1, 20, 200, 1000 pour des modèles entrainés avec SGD. Présentez dans un tableau la précision finale du modèle, sur l'*ensemble de validation*, pour ces différentes combinaisons d'hyperparamètres.\n",
        "\n",
        "- **Analyse du meilleur modèle:** Pour votre meilleur modèle, présentez deux figures montrant la progression de son apprentissage sur l'*ensembe d'entrainement et l'ensemble de validation*. La première figure montrant les courbes de log-vraisemblance négative moyenne après chaque epoch, la deuxième montrant la précision du modèle après chaque epoch. Finalement donnez la précision finale sur l'ensemble de test.\n",
        "\n",
        "- **Lire l'article de recherche -\n",
        "Adam**: a method for stochastic optimization. Kingma, D., \\& Ba, J. (2015). International Conference on Learning Representation (ICLR).\n",
        "https://arxiv.org/pdf/1412.6980.pdf. Implémentez Adam, répétez les deux étapes précédentes (recherche d'hyperparamètres et analyse du meilleur modèle) cette fois en utilisat Adam, et comparez les performances finales avec votre meilleur modèle SGD.\n",
        "\n",
        "**IMPORTANT**\n",
        "\n",
        "L'objectif du TP est de vous faire implémenter la rétropropagation à la main. **Il est donc interdit d'utiliser les capacités de construction de modèles ou de différentiation automatique de pytorch -- par exemple, aucun appels à torch.nn, torch.autograd ou à la méthode .backward().** L'objectif est d'implémenter un modèle de classification logistique ainsi que son entainement en utilisant uniquement des opérations matricielles de base fournies par PyTorch e.g. torch.sum(), torch.matmul(), etc."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fonctions fournies"
      ],
      "metadata": {
        "id": "oQq0nDgZuMfs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U_jhXT_0Cbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e9e8b45-4259-4479-9372-573410052319"
      },
      "source": [
        "# fonctions pour charger les ensembles de donnees\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=1):\n",
        "  dataset = FashionMNIST(\"./dataset\", train=True,  download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "  dataset_test = FashionMNIST(\"./dataset\", train=False,  download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "  len_train = int(len(dataset) * (1.-val_percentage))\n",
        "  len_val = len(dataset) - len_train\n",
        "  dataset_train, dataset_val = random_split(dataset, [len_train, len_val])\n",
        "  data_loader_train = DataLoader(dataset_train, batch_size=batch_size,shuffle=True,num_workers=4)\n",
        "  data_loader_val   = DataLoader(dataset_val, batch_size=batch_size,shuffle=True,num_workers=4)\n",
        "  data_loader_test  = DataLoader(dataset_test, batch_size=batch_size,shuffle=True,num_workers=4)\n",
        "  return data_loader_train, data_loader_val, data_loader_test\n",
        "\n",
        "def reshape_input(x, y):\n",
        "    x = x.view(-1, 784)\n",
        "    y = torch.FloatTensor(len(y), 10).zero_().scatter_(1,y.view(-1,1),1)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "# call this once first to download the datasets\n",
        "_ = get_fashion_mnist_dataloaders()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:00<00:00, 115MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 6.08MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 57.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 6.67MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H5BnbgAOpio"
      },
      "source": [
        "# simple logger to track progress during training\n",
        "class Logger:\n",
        "    def __init__(self):\n",
        "        self.losses_train = []\n",
        "        self.losses_valid = []\n",
        "        self.accuracies_train = []\n",
        "        self.accuracies_valid = []\n",
        "\n",
        "    def log(self, accuracy_train=0, loss_train=0, accuracy_valid=0, loss_valid=0):\n",
        "        self.losses_train.append(loss_train)\n",
        "        self.accuracies_train.append(accuracy_train)\n",
        "        self.losses_valid.append(loss_valid)\n",
        "        self.accuracies_valid.append(accuracy_valid)\n",
        "\n",
        "    def plot_loss_and_accuracy(self, train=True, valid=True):\n",
        "\n",
        "        assert train and valid, \"Cannot plot accuracy because neither train nor valid.\"\n",
        "\n",
        "        figure, (ax1, ax2) = plt.subplots(nrows=1, ncols=2,\n",
        "                                            figsize=(12, 6))\n",
        "\n",
        "        if train:\n",
        "            ax1.plot(self.losses_train, label=\"Training\")\n",
        "            ax2.plot(self.accuracies_train, label=\"Training\")\n",
        "        if valid:\n",
        "            ax1.plot(self.losses_valid, label=\"Validation\")\n",
        "            ax1.set_title(\"CrossEntropy Loss\")\n",
        "            ax2.plot(self.accuracies_valid, label=\"Validation\")\n",
        "            ax2.set_title(\"Accuracy\")\n",
        "\n",
        "        for ax in figure.axes:\n",
        "            ax.set_xlabel(\"Epoch\")\n",
        "            ax.legend(loc='best')\n",
        "            ax.set_axisbelow(True)\n",
        "            ax.minorticks_on()\n",
        "            ax.grid(True, which=\"major\", linestyle='-')\n",
        "            ax.grid(True, which=\"minor\", linestyle='--', color='lightgrey', alpha=.4)\n",
        "\n",
        "    def print_last(self):\n",
        "        print(f\"Epoch {len(self.losses_train):2d}, \\\n",
        "                Train:loss={self.losses_train[-1]:.3f}, accuracy={self.accuracies_train[-1]*100:.1f}%, \\\n",
        "                Valid: loss={self.losses_valid[-1]:.3f}, accuracy={self.losses_valid[-1]*100:.1f}%\", flush=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAJ5iiRUZw3f"
      },
      "source": [
        "## Aperçu de l'ensemble de données FashionMnist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "fK-eNmc8Zv2d",
        "outputId": "a02f8efb-cddd-4636-d8d6-923a9ce04e03"
      },
      "source": [
        "def plot_samples():\n",
        "  a, _, _ = get_fashion_mnist_dataloaders()\n",
        "  num_row = 2\n",
        "  num_col = 5# plot images\n",
        "  num_images = num_row * num_col\n",
        "  fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
        "  for i, (x,y) in enumerate(a):\n",
        "      if i >= num_images:\n",
        "        break\n",
        "      ax = axes[i//num_col, i%num_col]\n",
        "      x = (x.numpy().squeeze() * 255).astype(int)\n",
        "      y = y.numpy()[0]\n",
        "      ax.imshow(x, cmap='gray')\n",
        "      ax.set_title(f\"Label: {y}\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "plot_samples()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 750x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpZ8NK8_CAqW"
      },
      "source": [
        "## Fonctions à compléter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        " ***Crossentropy***\n",
        "\n",
        "Pour un vecteur one-hot $y$ et la prédiction (distrib de proba prédites) $y_{pred}$ on a l'erreur de cross entropy\n",
        "\n",
        "$-\\sum_{c=1}^K y_c \\log(y_{pred,c})$\n",
        "Donc pour avoir la loss sur un batch entier on fait la moyenne\n",
        "$-\\frac{1}{len(Batch)}\\sum_{i\\in Batch}\\sum_{c=1}^K y_c \\log(y_{pred,c})$\n"
      ],
      "metadata": {
        "id": "DXug6tGWUZrr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSc19WnyQsFv"
      },
      "source": [
        "def accuracy(y, y_pred) :\n",
        "    # todo : nombre d'éléments à classifier.\n",
        "    card_D = len(y)\n",
        "\n",
        "    # todo : calcul du nombre d'éléments bien classifiés.\n",
        "    y_pred_classes = torch.argmax(y_pred, dim=1)  # Indices des classes prédictes\n",
        "    y_true_classes = torch.argmax(y, dim=1)       # Indices des classes vraies\n",
        "    card_C = (y_pred_classes == y_true_classes).sum().item()\n",
        "\n",
        "    # todo : calcul de la précision de classification.\n",
        "    acc = card_C / card_D\n",
        "\n",
        "    return acc, (card_C, card_D)\n",
        "\n",
        "def accuracy_and_loss_whole_dataset(data_loader, model):\n",
        "    cardinal = 0\n",
        "    loss     = 0.\n",
        "    n_accurate_preds  = 0.\n",
        "\n",
        "    for x, y in data_loader:\n",
        "        x, y = reshape_input(x, y)\n",
        "        y_pred                = model.forward(x)\n",
        "        xentrp                = cross_entropy(y, y_pred)\n",
        "        _, (n_acc, n_samples) = accuracy(y, y_pred)\n",
        "\n",
        "        cardinal = cardinal + n_samples\n",
        "        loss     = loss + xentrp\n",
        "        n_accurate_preds  = n_accurate_preds + n_acc\n",
        "\n",
        "    loss = loss / float(cardinal)\n",
        "    acc  = n_accurate_preds / float(cardinal)\n",
        "\n",
        "    return acc, loss\n",
        "\n",
        "def cross_entropy(y, y_pred):\n",
        "    # todo : calcul de la valeur d'entropie croisée.\n",
        "    loss = -torch.sum(y * torch.log(y_pred + 1e-8)) / y.shape[0]\n",
        "    return loss\n",
        "\n",
        "def softmax(x, axis=-1):\n",
        "    # assurez vous que la fonction est numeriquement stable\n",
        "    # e.g. a\n",
        "    # todo : calcul des valeurs de softmax(x)\n",
        "\n",
        "    #On assume que les d'entrées sont les suivantes :\n",
        "\n",
        "    # x = [x_1, x_2 ... x_batchSize]\n",
        "    # x_1 = [w_observ1_classe0 . x_observ1_classe0 + b_observ1_classe0, w_observ1_classe1 . x_observ1_classe1 + b_observ1_classe1, ...]  (logit pour les différentes classes)\n",
        "\n",
        "    # Pour la stabilité comme softmax(x_i) = [exp(x_i[0]), exp(x_i[1]), ... , exp(x_i[K])] / sum(exp(x_i))\n",
        "    # si on divise en haut et en base bar exp(max(x_i)) on toujours l'égalité donc on peut juste retranché le logit le plus grand pour chaque batch afin d'avoir aucun exponentiel > 1 (non stable) à caculer\n",
        "\n",
        "    x_max = torch.amax(x, dim=axis, keepdim=True)\n",
        "    x_exp = torch.exp(x - x_max)\n",
        "    sum_exp = torch.sum(x_exp, dim=axis, keepdim=True)\n",
        "    values = x_exp / sum_exp\n",
        "    return values\n",
        "\n",
        "def inputs_tilde(x, axis=-1):\n",
        "    # augments the inputs `x` with ones along `axis`\n",
        "    # todo : implémenter code ici.\n",
        "    # On concatène une colonne de 1 pour le biais\n",
        "    ones = torch.ones(x.shape[0], 1)\n",
        "    x_tilde = torch.cat((x, ones), dim=axis)\n",
        "    return x_tilde"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax(torch.tensor([[1000, 10000, 100000]]), axis =1)\n",
        "# La stabilité est assurée et on a bien le résultat attentue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMj6mPPoz4jR",
        "outputId": "30728150-9cb6-4112-a70e-91976773780a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya7J-i89GHnp"
      },
      "source": [
        "class LinearModel:\n",
        "    def __init__(self, num_features, num_classes):\n",
        "      self.params = torch.normal(0, 0.01, (num_features + 1, num_classes))\n",
        "\n",
        "      self.t = 0\n",
        "      self.m_t = 0 # pour Adam: moyennes mobiles du gradient\n",
        "      self.v_t = 0 # pour Adam: moyennes mobiles du carré du gradient\n",
        "\n",
        "    def forward(self, x):\n",
        "      # todo : implémenter calcul des outputs en fonction des inputs `x`.\n",
        "\n",
        "      # Pour un batch de taille batchSize on a les dimensions suivantes :\n",
        "      # x                   : (batchSize, 784)\n",
        "      # inputs_tilde(x,1)   : (batchSize, 785)\n",
        "      # self.params (W)     : (785, 10)\n",
        "\n",
        "      # On veut des logits de dimension (batchSize, 10), il faut donc faire la multiplication matricielle\n",
        "      # logits = inputs_tilde(x,1) * self.params  (= x_augmented * W contrairement à w.x^T écris dans le cours)\n",
        "\n",
        "\n",
        "      inputs = inputs_tilde(x, 1)\n",
        "      logits = torch.matmul(inputs, self.params)\n",
        "      outputs = softmax(logits)\n",
        "      return outputs\n",
        "\n",
        "    def get_grads(self, y, y_pred, X):\n",
        "      # todo : implémenter calcul des gradients.\n",
        "\n",
        "      # On veut un gradient de la même dimension que W (self.params) i.e (785,10)\n",
        "      #\n",
        "      # On a les entrées de dimensions\n",
        "      # inputs_tilde(X,1) : (batchSize,785)\n",
        "      # y : (batchSize,10)\n",
        "      # y_pred : (batchSize, 10)\n",
        "      #\n",
        "      # Le gradient ce calcule donc comme\n",
        "      # inputs_tilde(X,1)^T * (y_pred - y)\n",
        "\n",
        "      grads = torch.matmul(torch.transpose(inputs_tilde(X, 1), 0, 1), (y_pred - y))\n",
        "      return grads\n",
        "\n",
        "    def sgd_update(self, lr, grads):\n",
        "      # TODO : implémenter mise à jour des paramètres ici.\n",
        "      self.params -= lr * grads\n",
        "\n",
        "    def adam_update(self, lr, grads):\n",
        "      beta1 = 0.9\n",
        "      beta2 = 0.999\n",
        "\n",
        "      self.t += 1\n",
        "      self.m_t = beta1 * self.m_t + (1 - beta1) * grads\n",
        "      self.v_t = beta2 * self.v_t + (1 - beta2) * (grads**2)\n",
        "      m = self.m_t / (1 - beta1)\n",
        "      v = self.v_t / (1 - beta2)\n",
        "      self.params -= lr * m / (torch.sqrt(v) + 1e-8)\n",
        "\n",
        "def train(model, lr=0.1, nb_epochs=10, sgd=True, data_loader_train=None, data_loader_val=None):\n",
        "    best_model = None\n",
        "    best_val_accuracy = 0\n",
        "    logger = Logger()\n",
        "\n",
        "    for epoch in range(nb_epochs+1):\n",
        "        # at epoch 0 evaluate random initial model\n",
        "        #   then for subsequent epochs, do optimize before evaluation.\n",
        "        if epoch > 0:\n",
        "          for x, y in data_loader_train:\n",
        "              x, y = reshape_input(x, y)\n",
        "              y_pred = model.forward(x)\n",
        "              loss = cross_entropy(y, y_pred)\n",
        "              grads = model.get_grads(y, y_pred, x)\n",
        "              if sgd:\n",
        "                model.sgd_update(lr, grads)\n",
        "              else:\n",
        "                model.adam_update(lr, grads)\n",
        "\n",
        "        accuracy_train, loss_train = accuracy_and_loss_whole_dataset(data_loader_train, model)\n",
        "        accuracy_val, loss_val = accuracy_and_loss_whole_dataset(data_loader_val, model)\n",
        "\n",
        "        if accuracy_val > best_val_accuracy:\n",
        "          best_val_accuracy = accuracy_val\n",
        "          best_model = model\n",
        "\n",
        "        logger.log(accuracy_train, loss_train, accuracy_val, loss_val)\n",
        "        print(f\"Epoch {epoch:2d}, \\\n",
        "                Train: loss={loss_train:.3f}, accuracy={accuracy_train*100:.1f}%, \\\n",
        "                Valid: loss={loss_val:.3f}, accuracy={accuracy_val*100:.1f}%\", flush=True)\n",
        "\n",
        "    return best_model, best_val_accuracy, logger\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Évaluation"
      ],
      "metadata": {
        "id": "_zUGBmtf9pcA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD: Recherche d'hyperparamètres"
      ],
      "metadata": {
        "id": "eUuU5n979pcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD\n",
        "# Montrez les résultats pour différents taux d'apprentissage, e.g. 0.1, 0.01, 0.001, et différentes tailles de mini-batch, e.g. 1, 20, 200, 1000.\n",
        "batch_size_list = [5, 25, 50, 300, 500]   # Define ranges in a list\n",
        "lr_list = [1, 0.1, 0.01, 0.001, 0.0001]           # Define ranges in a list\n",
        "\n",
        "with torch.no_grad():\n",
        "  for lr in lr_list:\n",
        "    for batch_size in batch_size_list:\n",
        "      print(\"------------------------------------------------------------------\")\n",
        "      print(\"Training model with a learning rate of {0} and a batch size of {1}\".format(lr, batch_size))\n",
        "      data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "      model = LinearModel(num_features=784, num_classes=10)\n",
        "      _, val_accuracy, _ = train(model,lr=lr, nb_epochs=5, sgd=True, data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "      print(f\"validation accuracy = {val_accuracy*100:.3f}\")"
      ],
      "metadata": {
        "id": "4R_6Rxgq9pcE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e5c5f9fa-13e2-42a5-dcca-72fe00ad0eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------\n",
            "Training model with a learning rate of 1 and a batch size of 5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-7a49bde757b1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_loader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_loader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"validation accuracy = {val_accuracy*100:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-4beacf2d675b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, lr, nb_epochs, sgd, data_loader_train, data_loader_val)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madam_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0maccuracy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_and_loss_whole_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0maccuracy_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_and_loss_whole_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-13377969be3e>\u001b[0m in \u001b[0;36maccuracy_and_loss_whole_dataset\u001b[0;34m(data_loader, model)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mn_accurate_preds\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0my_pred\u001b[0m                \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0mdigest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'md5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mWELCOME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAuthenticationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'digest sent was rejected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Tableau pour la précision sur l'ensemble de validation**\n",
        "N.B. que les lignes correspondent aux valeurs du taux d'apprentisage et les colonnes correspondent au valeur du batch size. Les valeurs ci-dessous sont donné comme exemples; remplacez-les par les valeurs que vous avez utilisées pour votre recherche d'hyperparamètres.\n",
        "\n",
        "learning rate\\batch_size  | 5       | 25     | 50     | 300    | 500 |\n",
        "--------------------------|---------|--------|--------|--------|-----|\n",
        "**1**                     | 83.150   | 83.100  | 83.450  | 82.033  | 80.750 |\n",
        "**0.1**                   | 83.133   | 81.217  | 82.933  | 81.350  | 80.300 |\n",
        "**0.01**                  | 83.033   | 82.917  | 83.617  | 83.883  | 79.250 |\n",
        "**0.001**                 | 84.517   | 84.000  | 84.400 | 83.883  | 79.083 |\n",
        "**0.0001**                | 81.400   | 80.683  | 81.633  | 81.067  | 81.200 |"
      ],
      "metadata": {
        "id": "AmvtxoLo9pcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD: Analyse du meilleur modèle"
      ],
      "metadata": {
        "id": "8PvrqlWt9pcG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ8Vc8JM9pcG"
      },
      "source": [
        "# SGD\n",
        "# Montrez les résultats pour la meilleure configuration trouvez ci-dessus.\n",
        "batch_size = 5 # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "lr = 0.001         # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "\n",
        "with torch.no_grad():\n",
        "  data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "  model = LinearModel(num_features=784, num_classes=10)\n",
        "  best_model, best_val_accuracy, logger = train(model,lr=lr, nb_epochs=5, sgd=True,\n",
        "                                                data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "  logger.plot_loss_and_accuracy()\n",
        "  print(f\"Best validation accuracy = {best_val_accuracy*100:.3f}\")\n",
        "\n",
        "  accuracy_test, loss_test = accuracy_and_loss_whole_dataset(data_loader_test, best_model)\n",
        "print(\"Evaluation of the best training model over test set\")\n",
        "print(\"------\")\n",
        "print(f\"Loss : {loss_test:.3f}\")\n",
        "print(f\"Accuracy : {accuracy_test*100.:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adam: Recherche d'hyperparamètres\n",
        "\n",
        "Implémentez Adam, répétez les deux étapes précédentes (recherche d'hyperparamètres et analyse du meilleur modèle) cette fois en utilisat Adam, et comparez les performances finales avec votre meilleur modèle SGD."
      ],
      "metadata": {
        "id": "BOZXfA919pcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM\n",
        "# Montrez les résultats pour différents taux d'apprentissage, e.g. 0.1, 0.01, 0.001, et différentes tailles de mini-batch, e.g. 1, 20, 200, 1000.\n",
        "batch_size_list = [5, 25, 50, 300, 500]   # Define ranges in a list\n",
        "lr_list = [1, 0.1, 0.01, 0.001, 0.0001]            # Define ranges in a list\n",
        "\n",
        "with torch.no_grad():\n",
        "  for lr in lr_list:\n",
        "    for batch_size in batch_size_list:\n",
        "      print(\"------------------------------------------------------------------\")\n",
        "      print(\"Training model with a learning rate of {0} and a batch size of {1}\".format(lr, batch_size))\n",
        "      data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "      model = LinearModel(num_features=784, num_classes=10)\n",
        "      _, val_accuracy, _ = train(model,lr=lr, nb_epochs=5, sgd=False, data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "      print(f\"validation accuracy = {val_accuracy*100:.3f}\")"
      ],
      "metadata": {
        "id": "Ze9D0Zpi9pcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Tableau pour la précision sur l'ensemble de validation**\n",
        "N.B. que les lignes correspondent aux valeurs du taux d'apprentisage et les colonnes correspondent au valeur du batch size. Les valeurs ci-dessous sont donné comme exemples; remplacez-les par les valeurs que vous avez utilisées pour votre recherche d'hyperparamètres.\n",
        "\n",
        "learning rate\\batch_size  | 5        | 25      | 50      | 300     | 500    |\n",
        "--------------------------|----------|---------|---------|---------|--------|\n",
        "**1**                     | 82.850   | 80.867  | 82.583  | 83.333  | 83.950 |\n",
        "**0.1**                   | 82.533   | 84.617  | 82.933  | 84.283  | 85.550 |\n",
        "**0.01**                  | 84.117   | 85.383  | 84.950  | 85.167  | 85.417 |\n",
        "**0.001**                 | 84.983   | 84.517  | 84.167  | 82.767  | 82.967 |\n",
        "**0.0001**                | 81.650   | 80.300  | 78.133  | 73.150  | 71.467 |"
      ],
      "metadata": {
        "id": "Cr9_MzpX_CvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adam: Analyse du meilleur modèle"
      ],
      "metadata": {
        "id": "2Me7IOblUrYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM\n",
        "# Montrez les résultats pour la meilleure configuration trouvez ci-dessus.\n",
        "batch_size = 500 # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "lr = 0.1         # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "\n",
        "with torch.no_grad():\n",
        "  data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "  model = LinearModel(num_features=784, num_classes=10)\n",
        "  best_model, best_val_accuracy, logger = train(model,lr=lr, nb_epochs=5, sgd=False,\n",
        "                                                data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "  logger.plot_loss_and_accuracy()\n",
        "  print(f\"Best validation accuracy = {best_val_accuracy*100:.3f}\")\n",
        "\n",
        "  accuracy_test, loss_test = accuracy_and_loss_whole_dataset(data_loader_test, best_model)\n",
        "print(\"Evaluation of the best training model over test set\")\n",
        "print(\"------\")\n",
        "print(f\"Loss : {loss_test:.3f}\")\n",
        "print(f\"Accuracy : {accuracy_test*100.:.3f}\")"
      ],
      "metadata": {
        "id": "Ndf_GP6XPV-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyse des Résultats"
      ],
      "metadata": {
        "id": "6LRkxtUD_RVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Répondez içi..."
      ],
      "metadata": {
        "id": "8NIRJe-8_fbP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IficnxEMMcNo"
      },
      "source": [
        "# Partie 3 (20 points)\n",
        "\n",
        "Pour cette partie, vous pouvez travailler en groupes de 2, mais il faut écrire sa propre dérivation et soumettre son propre rapport. Si vous travaillez avec un partenaire, il faut indiquer leur nom dans votre rapport."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zmb_putke8pl"
      },
      "source": [
        "### Problème"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRioLmIDMcP8"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=17_N7pIrf5pypQKiUh5cM7SX6raZUBcJC)\n",
        "\n",
        "Considérons maintenant un réseau de neurones avec une couche d'entrée avec $D=784$ unités, $L$ couches cachées, chacune avec 300 unités et un vecteur de sortie $\\mathbf{y}$ de dimension $K$. Vous avez $i = 1, .., N$ exemples dans un ensemble d'apprentissage, où chaque ${\\bf x}_i \\in \\mathbb{R}^{784}$ est un vecteur de caractéristiques (features). $\\mathbf{y}$ est un vecteur du type *one-hot* -- un vecteur de zéros avec un seul 1 pour indiquer que la classe $C=k$ dans la dimension $k$. Par exemple, le vecteur $\\mathbf{y}=[0, 1, 0, \\cdots, 0]^T$ représente la deuxième classe. La fonction de perte est donnée par\n",
        "\\begin{equation}\n",
        "\\mathscr{L} = -\\sum_{i=1}^{N}\\sum_{k=1}^{K}y_{k,i}\\log (f_k( {\\bf x}_i )  )\n",
        "\\end{equation}\n",
        "\n",
        "La fonction d'activation de la couche finale a la forme  ${\\bf f} = [f_1, ..., f_K]$ donné par la fonction d'activation softmax:\n",
        "\\begin{equation}\n",
        "f_k( {\\bf a}^{(L+1)}({\\bf x}_i) ) = \\frac{\\exp(a_k^{(L+1)})}{\\sum_{c=1}^{K}\\exp(a_c^{(L+1)})}, \\;\\;\\;\\;\n",
        "\\nonumber\n",
        "\\end{equation}\n",
        "\n",
        "et les couches cachées utilisent une fonction d'activation de type ReLU:\n",
        "\\begin{equation}\n",
        "  {\\bf h}^{(l)}({\\bf a}^{(l)}({\\bf x}_i)) = \\text{ReLU}({\\bf a}^{(l)}({\\bf x}_i) = \\max\\Big(0, \\, \\, {\\bf a}^{(l)}({\\bf x}_i)\\Big)\n",
        "\\end{equation}\n",
        "\n",
        "où ${\\bf a}^{(l)}$ est le vecteur résultant du calcul de la préactivation habituelle ${\\bf a}^{(l)}={\\bf W}^{(l)}{\\bf h}^{(l-1)} + {\\bf b}^{(l)}$, qui pourrait être simplifiée à ${\\boldsymbol \\theta}^{(l)}\\tilde{\\bf h}^{(l-1)}$ en utilisant l'astuce de définir $\\tilde{\\bf h}$ comme ${\\bf h}$ avec un 1 concaténé à la fin du vecteur.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzMpz3Zse0t9"
      },
      "source": [
        "### Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK8gnygxMcSh"
      },
      "source": [
        "* a) (10 points) Donnez le pseudocode incluant des *calculs matriciels—vectoriels* détaillés pour l'algorithme de rétropropagation pour calculer le gradient pour les paramètres de chaque couche **étant donné un exemple d'entraînement**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y431_w4gMcX2"
      },
      "source": [
        "* b) (15 points)\n",
        "Implémentez l'optimisation basée sur le gradient de ce réseau en Pytorch.\n",
        "Utilisez le code squelette ci-dessous comme point de départ et implémentez les mathématiques de l'algorithme de rétropropagation que vous avez décrit à la question précédente. Comparez vos gradients et votre optimisation avec le même modèle optimisé avec Autograd. Lequel est le plus rapide ? Proposez quelques expériences. Utilisez encore l'ensemble de données de Fashion MNIST (voir Partie 2). **Comparez différents modèles ayant différentes largeurs (nombre d'unités) et profondeurs (nombre de couches)**. Ici encore, n'utilisez l'ensemble de test que pour votre expérience finale lorsque vous pensez avoir obtenu votre meilleur modèle.\n",
        "\n",
        "\n",
        "**IMPORTANT**\n",
        "\n",
        "L'objectif du TP est de vous faire implémenter la rétropropagation à la main. L'objectif est d'implémenter un modèle de classification logistique ainsi que son entainement en utilisant uniquement des opérations matricielles de base fournies par PyTorch e.g. torch.sum(), torch.matmul(), etc. **Une fois que vous avez implémenté votre modèle, vous devez le comparer avec un modèle construit en utilisant les capacités de pytorch qui permettent une différenciation automatique. Autrement dit, pour la deuxième implémentation, vous pouvez utilisertorch.nn, torch.autograd ou à la méthode .backward().** Vous pouvez utiliser l’implémentation de votre choix pour explorer différentes architectures de modèles."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Votre pseudocode:"
      ],
      "metadata": {
        "id": "F1mpuG2cwER-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Algorithme de rétropopagation dans un réseau de neurones pour un exemple $\\tilde{x}_i$:\n",
        "\n",
        "1. TODO\n",
        "2. TODO\n",
        "3. TODO..."
      ],
      "metadata": {
        "id": "qY2X9goYwMDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fonctions à compléter"
      ],
      "metadata": {
        "id": "SIQJD-TRwEdo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzIQ0S4qDPKJ"
      },
      "source": [
        "''' Les fonctions dans cette cellule peuvent avoir les mêmes déclarations que celles de la partie 2'''\n",
        "def accuracy(y, y_pred) :\n",
        "    # todo : nombre d'éléments à classifier.\n",
        "    card_D = len(y)\n",
        "\n",
        "    # todo : calcul du nombre d'éléments bien classifiés.\n",
        "    y_pred_classes = torch.argmax(y_pred, dim=1)  # Indices des classes prédictes\n",
        "    y_true_classes = torch.argmax(y, dim=1)       # Indices des classes vraies\n",
        "    card_C = (y_pred_classes == y_true_classes).sum().item()\n",
        "\n",
        "    # todo : calcul de la précision de classification.\n",
        "    acc = card_C / card_D\n",
        "\n",
        "    return acc, (card_C, card_D)\n",
        "\n",
        "def accuracy_and_loss_whole_dataset(data_loader, model):\n",
        "    cardinal = 0\n",
        "    loss     = 0.\n",
        "    n_accurate_preds  = 0.\n",
        "\n",
        "    for x, y in data_loader:\n",
        "        x, y = reshape_input(x, y)\n",
        "        y_pred                = model.forward(x)\n",
        "        xentrp                = cross_entropy(y, y_pred)\n",
        "        _, (n_acc, n_samples) = accuracy(y, y_pred)\n",
        "\n",
        "        cardinal = cardinal + n_samples\n",
        "        loss     = loss + xentrp\n",
        "        n_accurate_preds  = n_accurate_preds + n_acc\n",
        "\n",
        "    loss = loss / float(cardinal)\n",
        "    acc  = n_accurate_preds / float(cardinal)\n",
        "\n",
        "    return acc, loss\n",
        "\n",
        "def inputs_tilde(x, axis=-1):\n",
        "    # augments the inputs `x` with ones along `axis`\n",
        "    # todo : implémenter code ici.\n",
        "    # On concatène une colonne de 1 pour le biais\n",
        "    ones = torch.ones(x.shape[0], 1)\n",
        "    x_tilde = torch.cat((x, ones), dim=axis)\n",
        "    return x_tilde\n",
        "\n",
        "def softmax(x, axis=-1):\n",
        "    # assurez vous que la fonction est numeriquement stable\n",
        "    # e.g. softmax(np.array([1000, 10000, 100000], ndim=2))\n",
        "    # todo : calcul des valeurs de softmax(x)\n",
        "\n",
        "    #On assume que les d'entrées sont les suivantes :\n",
        "\n",
        "    # x = [x_1, x_2 ... x_batchSize]\n",
        "    # x_1 = [w_observ1_classe0 . x_observ1_classe0 + b_observ1_classe0, w_observ1_classe1 . x_observ1_classe1 + b_observ1_classe1, ...]  (logit pour les différentes classes)\n",
        "\n",
        "    # Pour la stabilité comme softmax(x_i) = [exp(x_i[0]), exp(x_i[1]), ... , exp(x_i[K])] / sum(exp(x_i))\n",
        "    # si on divise en haut et en base bar exp(max(x_i)) on toujours l'égalité donc on peut juste retranché le logit le plus grand pour chaque batch afin d'avoir aucun exponentiel > 1 (non stable) à caculer\n",
        "\n",
        "    x_max = torch.amax(x, dim=axis, keepdim=True)\n",
        "    x_exp = torch.exp(x - x_max)\n",
        "    sum_exp = torch.sum(x_exp, dim=axis, keepdim=True)\n",
        "    values = x_exp / sum_exp\n",
        "    return values\n",
        "\n",
        "def cross_entropy(y, y_pred):\n",
        "    # todo : calcul de la valeur d'entropie croisée.\n",
        "    loss = -torch.sum(y * torch.log(y_pred + 1e-8)) / y.shape[0]\n",
        "    return loss\n",
        "\n",
        "def softmax_cross_entropy_backward(y, y_pred):\n",
        "     # todo : calcul de la valeur du gradient de l'entropie croisée composée avec `softmax`\n",
        "     # On a L = -\\sum_k y_k log(softmax_k) et on a montré que ce gradiant par rapport aux pré-activation (les a^(L+1) avant le softmax) donne\n",
        "     # dL/da^(L+1) = -\\Delta^(L+1) = -(y-y_pred)\n",
        "     values = -(y-y_pred)\n",
        "     return values\n",
        "\n",
        "def relu_forward(x):\n",
        "    # todo : calcul des valeurs de relu(x)\n",
        "    # Relu c'est juste le max valeurs par valeurs entre 0 et les valeurs de x, on évite d'utiliser torch.relu pour essayer de tout faire le plus possible à la main pour bien comprendre\n",
        "    values = torch.maximum(x, torch.tensor(0.0))\n",
        "    return values\n",
        "\n",
        "def relu_backward(x):\n",
        "    # todo : calcul des valeurs du gradient de la fonction `relu`\n",
        "    values = (x > 0).float()  # 1 si x > 0, sinon 0\n",
        "    return values\n",
        "\n",
        "\n",
        "# Model est une classe representant votre reseaux de neuronnes\n",
        "class MLPModel:\n",
        "    def __init__(self, n_features, n_hidden_features, n_hidden_layers, n_classes):\n",
        "        self.n_features        = n_features\n",
        "        self.n_hidden_features = n_hidden_features\n",
        "        self.n_hidden_layers   = n_hidden_layers\n",
        "        self.n_classes         = n_classes\n",
        "\n",
        "        # todo : initialiser la liste des paramètres Teta de l'estimateur.\n",
        "\n",
        "\n",
        "        self.params = []\n",
        "\n",
        "        # première couche theta^(1) : (n_hidden_features, n_features+1)\n",
        "        self.params.append(torch.randn(n_hidden_features, n_features+1) * torch.sqrt(torch.tensor(2.0 / (n_features+1))))\n",
        "\n",
        "        # Couches cachées theta^(l) : (n_hidden_features, n_hidden_features + 1)\n",
        "        for _ in range(n_hidden_layers - 1):\n",
        "            self.params.append(torch.randn(n_hidden_features, n_hidden_features + 1) * torch.sqrt(torch.tensor(2.0 / (n_hidden_features + 1))))\n",
        "\n",
        "        # dernière couche theta^(L+1) : (n_classes, n_hidden_features + 1)\n",
        "        self.params.append(torch.randn(n_classes, n_hidden_features + 1) * torch.sqrt(torch.tensor(2.0 / (n_hidden_features + 1))))\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"Teta params={[p.shape for p in self.params]}\")\n",
        "\n",
        "        self.a = None # liste contenant le resultat des multiplications matricielles\n",
        "        self.h = None # liste contenant le resultat des fonctions d'activations\n",
        "\n",
        "        self.t = 0\n",
        "        self.m_t = 0 # pour Adam: moyennes mobiles du gradient\n",
        "        self.v_t = 0 # pour Adam: moyennes mobiles du carré du gradient\n",
        "\n",
        "    def forward(self, x):\n",
        "      # print(\"__________. DEBUG FORWARD .__________ \")\n",
        "      # print(f\"x : {x}\")\n",
        "\n",
        "      self.a = []\n",
        "      self.h = []\n",
        "      h = inputs_tilde(x, 1)\n",
        "      h = torch.transpose(h, 0, 1)\n",
        "      self.h.append(h)\n",
        "      # print(f\"h^(0) : {h}\")\n",
        "      l = 0\n",
        "      for theta in self.params[:-1]:\n",
        "        l+= 1\n",
        "        # print(f\"=== L = {l}\")\n",
        "        # print(f\"theta^({l}) shape : {theta.shape}\")\n",
        "        # print(theta)\n",
        "        a = torch.matmul(theta, h)\n",
        "        # print(f\"a^({l}) shape : {a.shape}\")\n",
        "        # print(a)\n",
        "        self.a.append(a)\n",
        "        h = relu_forward(a)\n",
        "        h = torch.transpose(h, 0, 1)\n",
        "        h = inputs_tilde(h, 1)\n",
        "        h = torch.transpose(h, 0, 1)\n",
        "        # print(f\"h^({l}) shape : {h.shape}\")\n",
        "        # print(h)\n",
        "\n",
        "        self.h.append(h)\n",
        "\n",
        "      # print(f\"=== L = L+1 = {l+1}\")\n",
        "      # print(f\"theta^({l+1}) shape : {self.params[-1].shape}\")\n",
        "      a = torch.matmul(self.params[-1], h)\n",
        "      self.a.append(a)\n",
        "      # print(f\"a^({l+1}) shape : {a.shape}\")\n",
        "      # print(a)\n",
        "      outputs = softmax(torch.transpose(a,0,1), 1)\n",
        "      # print(f\"outputs : {outputs}\")\n",
        "\n",
        "      return outputs\n",
        "\n",
        "    def backward(self, y, y_pred):\n",
        "      # todo : implémenter calcul des gradients.\n",
        "\n",
        "      #On fait les calcules comme si on avait un batch de taille 1 et donc des vecteurs colonnes pour les couches\n",
        "      y_pred = torch.transpose(y_pred,0,1)\n",
        "      y = torch.transpose(y,0,1)\n",
        "\n",
        "      # print(\"______________. debug backward .______________\")\n",
        "      # print(f\"y_pred shapes : {[y_pred.shape]} - y_pred : {y_pred}\")\n",
        "      # print(f\"y shapes : {[y.shape]} - y : {y}\")\n",
        "      # print(\"self.params : \", len(self.params), self.params[0].shape, self.params[1].shape, self.params[-1].shape)\n",
        "      # for i in range(len(self.params)):\n",
        "      #   print(f\"theta i={i}\")\n",
        "      #   print(self.params[i])\n",
        "\n",
        "      # print(\"self.a : \", len(self.a), self.a[0].shape, self.a[1].shape, self.a[-1].shape)\n",
        "      # for i in range(len(self.a)):\n",
        "      #   print(f\"a i={i}\")\n",
        "      #   print(self.a[i])\n",
        "\n",
        "      # print(\"self.h : \", len(self.h), self.h[0].shape, self.h[1].shape, self.h[-2].shape, self.h[-1].shape)\n",
        "      # for i in range(len(self.h)):\n",
        "      #   print(f\"h i={i}\")\n",
        "      #   print(self.h[i])\n",
        "\n",
        "\n",
        "      # print(\"INITIALISATION : OK ✅ \")\n",
        "      delta = - softmax_cross_entropy_backward(y, y_pred)\n",
        "      # print(f\"delta.shape : {delta.shape} - {delta} \\n\")\n",
        "      gradinit = - torch.matmul(delta, torch.transpose(self.h[-1],0,1))\n",
        "      # print(f\"grad.shape : {gradinit.shape} - {gradinit}\\n\")\n",
        "      deltas = [delta]\n",
        "      grads = []\n",
        "      for i in range(len(self.params)):\n",
        "        l = len(self.params)-1 - i\n",
        "        # print(f\"-- L : {l} --\")\n",
        "        if l != len(self.params)-1:\n",
        "          # calculer delta^(l) en fonction du suivant delta^(l+1)\n",
        "          dl = relu_backward(self.a[l]) #vecteur issue de la matrice D^(l) issue de dh^(l)/da^(l)\n",
        "          W_next = self.params[l+1][:,:-1]\n",
        "          mult = torch.matmul(torch.transpose(W_next, 0,1), delta)\n",
        "          # print(f\"d^({l}): {dl.shape} - {dl}\")\n",
        "          # print(f\"W^({l+1}): {W_next.shape} - {W_next}\")\n",
        "          # print(f\"mult^({l+1}): {mult.shape} - {mult}\")\n",
        "          delta = dl * mult\n",
        "          # print(f\"delta^({l}) : {delta.shape} - {delta}\\n\")\n",
        "          deltas.append(delta)\n",
        "\n",
        "        grad = -torch.matmul(delta, torch.transpose(self.h[l],0,1))   #pas besoin de mettre h[l-1] car les h sont indicé en décalé par rapport au W et a car on a mis l'input tilde dans h au début et pas l'output\n",
        "        # print(f\"grad.shape : {grad.shape}\", \"\\n\")\n",
        "        grads.append(grad)\n",
        "\n",
        "      list.reverse(grads)\n",
        "      return grads\n",
        "\n",
        "    def sgd_update(self, lr, grads):\n",
        "      # TODO : implémenter mise à jour des paramètres ici.\n",
        "      # print(f\"grads shapes : {[g.shape for g in grads]}\")\n",
        "      # print(f\"params shapes : {[param.shape for param in self.params]}\")\n",
        "      # print(\"======= . Update . =======\")\n",
        "      # print(f\"grad[0] : {grads[0]} - grad[1] : {grads[1]} - grad[-1] : {grads[-1]}\")\n",
        "      # print(f\"self.params[0] : {self.params[0]} - self.params[1] : {self.params[1]} - self.params[-1] : {self.params[-1]}\")\n",
        "\n",
        "\n",
        "\n",
        "      for i in range(len(self.params)):\n",
        "        self.params[i] -= lr * grads[i]\n",
        "\n",
        "\n",
        "    def adam_update(self, lr, grads):\n",
        "      # TODO : implémenter mise à jour des paramètres ici.\n",
        "      beta1 = 0.9\n",
        "      beta2 = 0.999\n",
        "\n",
        "      self.t += 1\n",
        "      self.m_t = beta1 * self.m_t + (1 - beta1) * grads\n",
        "      self.v_t = beta2 * self.v_t + (1 - beta2) * (grads**2)\n",
        "      m = self.m_t / (1 - beta1)\n",
        "      v = self.v_t / (1 - beta2)\n",
        "      for i in range(len(self.params)):\n",
        "        self.params[i] -= lr * m[i] / (torch.sqrt(v[i]) + 1e-8)\n",
        "\n",
        "def train(model, lr=0.1, nb_epochs=10, sgd=True, data_loader_train=None, data_loader_val=None):\n",
        "    best_model = None\n",
        "    best_val_accuracy = 0\n",
        "    logger = Logger()\n",
        "\n",
        "    for epoch in range(nb_epochs+1):\n",
        "\n",
        "        # at epoch 0 evaluate random initial model\n",
        "        #   then for subsequent epochs, do optimize before evaluation.\n",
        "        if epoch > 0:\n",
        "            for x, y in data_loader_train:\n",
        "                x, y = reshape_input(x, y)\n",
        "\n",
        "                y_pred = model.forward(x)\n",
        "                grads  = model.backward(y, y_pred)\n",
        "                if sgd:\n",
        "                  model.sgd_update(lr, grads)\n",
        "                else:\n",
        "                  model.adam_update(lr, grads)\n",
        "\n",
        "        accuracy_train, loss_train = accuracy_and_loss_whole_dataset(data_loader_train, model)\n",
        "        accuracy_val, loss_val = accuracy_and_loss_whole_dataset(data_loader_val, model)\n",
        "\n",
        "        if accuracy_val > best_val_accuracy:\n",
        "          best_val_accuracy = accuracy_val\n",
        "          best_model = model\n",
        "\n",
        "        logger.log(accuracy_train, loss_train, accuracy_val, loss_val)\n",
        "        print(f\"Epoch {epoch:2d}, \\\n",
        "                Train:loss={loss_train:.3f}, accuracy={accuracy_train*100:.1f}%, \\\n",
        "                Valid: loss={loss_val:.3f}, accuracy={accuracy_val*100:.1f}%\", flush=True)\n",
        "\n",
        "    return best_model, best_val_accuracy, logger"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Évaluation"
      ],
      "metadata": {
        "id": "tIe9DFvPwuQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD: Recherche d'hyperparamètres"
      ],
      "metadata": {
        "id": "ml5jUvG9AUXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD\n",
        "# Montrez les résultats pour différents nombre de couche, e.g. 1, 3, 5, et différent nombres de neurone, e.g. 25, 100, 300, 500, 1000.\n",
        "depth_list = [1,3,5]   # Define ranges in a list\n",
        "width_list = [25, 100, 300, 500, 1000]   # Define ranges in a list\n",
        "lr = 0.001           # Some value\n",
        "batch_size = 20   # Some value\n",
        "\n",
        "with torch.no_grad():\n",
        "  for depth in depth_list:\n",
        "    for width in width_list:\n",
        "      print(\"------------------------------------------------------------------\")\n",
        "      print(\"Training model with a depth of {0} layers and a width of {1} units\".format(depth, width))\n",
        "      data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "      MLP_model = MLPModel(n_features=784, n_hidden_features=width, n_hidden_layers=depth, n_classes=10)\n",
        "      _, val_accuracy, _ = train(MLP_model,lr=lr, nb_epochs=5, sgd=True, data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "      print(f\"validation accuracy = {val_accuracy*100:.3f}\")"
      ],
      "metadata": {
        "id": "fe7hyN63AUXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff50089-002b-4f21-c67f-618edd339b66"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------\n",
            "Training model with a depth of 1 layers and a width of 25 units\n",
            "Teta params=[torch.Size([25, 785]), torch.Size([10, 26])]\n",
            "Epoch  0,                 Train:loss=0.124, accuracy=7.7%,                 Valid: loss=0.124, accuracy=8.1%\n",
            "Epoch  1,                 Train:loss=0.025, accuracy=83.0%,                 Valid: loss=0.024, accuracy=82.7%\n",
            "Epoch  2,                 Train:loss=0.023, accuracy=84.0%,                 Valid: loss=0.023, accuracy=83.4%\n",
            "Epoch  3,                 Train:loss=0.021, accuracy=85.1%,                 Valid: loss=0.022, accuracy=84.5%\n",
            "Epoch  4,                 Train:loss=0.020, accuracy=85.7%,                 Valid: loss=0.021, accuracy=85.0%\n",
            "Epoch  5,                 Train:loss=0.020, accuracy=85.5%,                 Valid: loss=0.021, accuracy=84.9%\n",
            "validation accuracy = 0.000\n",
            "------------------------------------------------------------------\n",
            "Training model with a depth of 1 layers and a width of 100 units\n",
            "Teta params=[torch.Size([100, 785]), torch.Size([10, 101])]\n",
            "Epoch  0,                 Train:loss=0.135, accuracy=13.0%,                 Valid: loss=0.136, accuracy=12.7%\n",
            "Epoch  1,                 Train:loss=0.024, accuracy=83.0%,                 Valid: loss=0.024, accuracy=82.8%\n",
            "Epoch  2,                 Train:loss=0.021, accuracy=85.3%,                 Valid: loss=0.021, accuracy=85.1%\n",
            "Epoch  3,                 Train:loss=0.019, accuracy=86.4%,                 Valid: loss=0.020, accuracy=85.9%\n",
            "Epoch  4,                 Train:loss=0.019, accuracy=86.1%,                 Valid: loss=0.020, accuracy=85.5%\n",
            "Epoch  5,                 Train:loss=0.017, accuracy=88.1%,                 Valid: loss=0.018, accuracy=87.7%\n",
            "validation accuracy = 0.000\n",
            "------------------------------------------------------------------\n",
            "Training model with a depth of 1 layers and a width of 300 units\n",
            "Teta params=[torch.Size([300, 785]), torch.Size([10, 301])]\n",
            "Epoch  0,                 Train:loss=0.128, accuracy=10.6%,                 Valid: loss=0.128, accuracy=11.5%\n",
            "Epoch  1,                 Train:loss=0.024, accuracy=83.8%,                 Valid: loss=0.023, accuracy=84.4%\n",
            "Epoch  2,                 Train:loss=0.021, accuracy=84.8%,                 Valid: loss=0.022, accuracy=84.3%\n",
            "Epoch  3,                 Train:loss=0.019, accuracy=86.9%,                 Valid: loss=0.019, accuracy=86.9%\n",
            "Epoch  4,                 Train:loss=0.018, accuracy=87.3%,                 Valid: loss=0.019, accuracy=87.0%\n",
            "Epoch  5,                 Train:loss=0.017, accuracy=87.9%,                 Valid: loss=0.018, accuracy=87.4%\n",
            "validation accuracy = 0.000\n",
            "------------------------------------------------------------------\n",
            "Training model with a depth of 1 layers and a width of 500 units\n",
            "Teta params=[torch.Size([500, 785]), torch.Size([10, 501])]\n",
            "Epoch  0,                 Train:loss=0.123, accuracy=10.6%,                 Valid: loss=0.123, accuracy=11.1%\n",
            "Epoch  1,                 Train:loss=0.022, accuracy=84.5%,                 Valid: loss=0.023, accuracy=84.1%\n",
            "Epoch  2,                 Train:loss=0.020, accuracy=85.9%,                 Valid: loss=0.021, accuracy=85.4%\n",
            "Epoch  3,                 Train:loss=0.018, accuracy=87.2%,                 Valid: loss=0.019, accuracy=86.1%\n",
            "Epoch  4,                 Train:loss=0.017, accuracy=87.9%,                 Valid: loss=0.019, accuracy=87.0%\n",
            "Epoch  5,                 Train:loss=0.017, accuracy=88.5%,                 Valid: loss=0.018, accuracy=87.5%\n",
            "validation accuracy = 0.000\n",
            "------------------------------------------------------------------\n",
            "Training model with a depth of 1 layers and a width of 1000 units\n",
            "Teta params=[torch.Size([1000, 785]), torch.Size([10, 1001])]\n",
            "Epoch  0,                 Train:loss=0.133, accuracy=4.1%,                 Valid: loss=0.133, accuracy=4.3%\n",
            "Epoch  1,                 Train:loss=0.022, accuracy=84.9%,                 Valid: loss=0.023, accuracy=84.9%\n",
            "Epoch  2,                 Train:loss=0.020, accuracy=86.2%,                 Valid: loss=0.020, accuracy=85.5%\n",
            "Epoch  3,                 Train:loss=0.018, accuracy=87.5%,                 Valid: loss=0.018, accuracy=86.8%\n",
            "Epoch  4,                 Train:loss=0.017, accuracy=88.1%,                 Valid: loss=0.018, accuracy=87.0%\n",
            "Epoch  5,                 Train:loss=0.016, accuracy=89.0%,                 Valid: loss=0.017, accuracy=87.9%\n",
            "validation accuracy = 0.000\n",
            "------------------------------------------------------------------\n",
            "Training model with a depth of 3 layers and a width of 25 units\n",
            "Teta params=[torch.Size([25, 785]), torch.Size([25, 26]), torch.Size([25, 26]), torch.Size([10, 26])]\n",
            "Epoch  0,                 Train:loss=0.128, accuracy=10.8%,                 Valid: loss=0.128, accuracy=10.7%\n",
            "Epoch  1,                 Train:loss=0.026, accuracy=81.0%,                 Valid: loss=0.027, accuracy=80.6%\n",
            "Epoch  2,                 Train:loss=0.021, accuracy=85.2%,                 Valid: loss=0.021, accuracy=85.5%\n",
            "Epoch  3,                 Train:loss=0.019, accuracy=86.3%,                 Valid: loss=0.020, accuracy=85.7%\n",
            "Epoch  4,                 Train:loss=0.020, accuracy=85.4%,                 Valid: loss=0.020, accuracy=84.8%\n",
            "Epoch  5,                 Train:loss=0.018, accuracy=87.2%,                 Valid: loss=0.019, accuracy=86.5%\n",
            "validation accuracy = 0.000\n",
            "------------------------------------------------------------------\n",
            "Training model with a depth of 3 layers and a width of 100 units\n",
            "Teta params=[torch.Size([100, 785]), torch.Size([100, 101]), torch.Size([100, 101]), torch.Size([10, 101])]\n",
            "Epoch  0,                 Train:loss=0.121, accuracy=10.4%,                 Valid: loss=0.120, accuracy=10.8%\n",
            "Epoch  1,                 Train:loss=0.020, accuracy=85.3%,                 Valid: loss=0.021, accuracy=85.1%\n",
            "Epoch  2,                 Train:loss=0.019, accuracy=86.3%,                 Valid: loss=0.020, accuracy=86.3%\n",
            "Epoch  3,                 Train:loss=0.018, accuracy=86.7%,                 Valid: loss=0.020, accuracy=86.1%\n",
            "Epoch  4,                 Train:loss=0.016, accuracy=88.0%,                 Valid: loss=0.017, accuracy=87.0%\n",
            "Epoch  5,                 Train:loss=0.015, accuracy=88.9%,                 Valid: loss=0.017, accuracy=87.8%\n",
            "validation accuracy = 0.000\n",
            "------------------------------------------------------------------\n",
            "Training model with a depth of 3 layers and a width of 300 units\n",
            "Teta params=[torch.Size([300, 785]), torch.Size([300, 301]), torch.Size([300, 301]), torch.Size([10, 301])]\n",
            "Epoch  0,                 Train:loss=0.127, accuracy=8.1%,                 Valid: loss=0.128, accuracy=7.9%\n",
            "Epoch  1,                 Train:loss=0.021, accuracy=85.1%,                 Valid: loss=0.022, accuracy=84.1%\n",
            "Epoch  2,                 Train:loss=0.017, accuracy=87.4%,                 Valid: loss=0.019, accuracy=86.8%\n",
            "Epoch  3,                 Train:loss=0.016, accuracy=88.5%,                 Valid: loss=0.018, accuracy=86.9%\n",
            "Epoch  4,                 Train:loss=0.016, accuracy=88.3%,                 Valid: loss=0.018, accuracy=86.7%\n",
            "Epoch  5,                 Train:loss=0.014, accuracy=90.0%,                 Valid: loss=0.016, accuracy=88.4%\n",
            "validation accuracy = 0.000\n",
            "------------------------------------------------------------------\n",
            "Training model with a depth of 3 layers and a width of 500 units\n",
            "Teta params=[torch.Size([500, 785]), torch.Size([500, 501]), torch.Size([500, 501]), torch.Size([10, 501])]\n",
            "Epoch  0,                 Train:loss=0.131, accuracy=5.4%,                 Valid: loss=0.131, accuracy=5.8%\n",
            "Epoch  1,                 Train:loss=0.021, accuracy=84.5%,                 Valid: loss=0.021, accuracy=84.2%\n",
            "Epoch  2,                 Train:loss=0.017, accuracy=87.9%,                 Valid: loss=0.017, accuracy=87.1%\n",
            "Epoch  3,                 Train:loss=0.017, accuracy=87.3%,                 Valid: loss=0.018, accuracy=86.1%\n",
            "Epoch  4,                 Train:loss=0.014, accuracy=89.6%,                 Valid: loss=0.016, accuracy=88.2%\n",
            "Epoch  5,                 Train:loss=0.013, accuracy=90.4%,                 Valid: loss=0.015, accuracy=88.5%\n",
            "validation accuracy = 0.000\n",
            "------------------------------------------------------------------\n",
            "Training model with a depth of 3 layers and a width of 1000 units\n",
            "Teta params=[torch.Size([1000, 785]), torch.Size([1000, 1001]), torch.Size([1000, 1001]), torch.Size([10, 1001])]\n",
            "Epoch  0,                 Train:loss=0.116, accuracy=10.6%,                 Valid: loss=0.117, accuracy=10.8%\n",
            "Epoch  1,                 Train:loss=0.019, accuracy=86.1%,                 Valid: loss=0.020, accuracy=85.1%\n",
            "Epoch  2,                 Train:loss=0.016, accuracy=88.3%,                 Valid: loss=0.018, accuracy=87.6%\n",
            "Epoch  3,                 Train:loss=0.014, accuracy=89.6%,                 Valid: loss=0.016, accuracy=88.1%\n",
            "Epoch  4,                 Train:loss=0.014, accuracy=90.0%,                 Valid: loss=0.016, accuracy=88.2%\n",
            "Epoch  5,                 Train:loss=0.013, accuracy=90.9%,                 Valid: loss=0.016, accuracy=88.8%\n",
            "validation accuracy = 0.000\n",
            "------------------------------------------------------------------\n",
            "Training model with a depth of 5 layers and a width of 25 units\n",
            "Teta params=[torch.Size([25, 785]), torch.Size([25, 26]), torch.Size([25, 26]), torch.Size([25, 26]), torch.Size([25, 26]), torch.Size([10, 26])]\n",
            "Epoch  0,                 Train:loss=0.130, accuracy=6.7%,                 Valid: loss=0.130, accuracy=6.7%\n",
            "Epoch  1,                 Train:loss=0.023, accuracy=83.9%,                 Valid: loss=0.023, accuracy=83.4%\n",
            "Epoch  2,                 Train:loss=0.021, accuracy=84.8%,                 Valid: loss=0.022, accuracy=84.3%\n",
            "Epoch  3,                 Train:loss=0.020, accuracy=85.5%,                 Valid: loss=0.021, accuracy=84.6%\n",
            "Epoch  4,                 Train:loss=0.018, accuracy=87.1%,                 Valid: loss=0.019, accuracy=86.7%\n",
            "Epoch  5,                 Train:loss=0.019, accuracy=85.9%,                 Valid: loss=0.021, accuracy=84.5%\n",
            "validation accuracy = 0.000\n",
            "------------------------------------------------------------------\n",
            "Training model with a depth of 5 layers and a width of 100 units\n",
            "Teta params=[torch.Size([100, 785]), torch.Size([100, 101]), torch.Size([100, 101]), torch.Size([100, 101]), torch.Size([100, 101]), torch.Size([10, 101])]\n",
            "Epoch  0,                 Train:loss=0.128, accuracy=6.9%,                 Valid: loss=0.129, accuracy=7.1%\n",
            "Epoch  1,                 Train:loss=0.026, accuracy=80.7%,                 Valid: loss=0.027, accuracy=80.4%\n",
            "Epoch  2,                 Train:loss=0.018, accuracy=86.5%,                 Valid: loss=0.019, accuracy=86.2%\n",
            "Epoch  3,                 Train:loss=0.018, accuracy=87.0%,                 Valid: loss=0.020, accuracy=85.9%\n",
            "Epoch  4,                 Train:loss=0.015, accuracy=89.0%,                 Valid: loss=0.016, accuracy=87.8%\n",
            "Epoch  5,                 Train:loss=0.014, accuracy=89.3%,                 Valid: loss=0.016, accuracy=88.0%\n",
            "validation accuracy = 0.000\n",
            "------------------------------------------------------------------\n",
            "Training model with a depth of 5 layers and a width of 300 units\n",
            "Teta params=[torch.Size([300, 785]), torch.Size([300, 301]), torch.Size([300, 301]), torch.Size([300, 301]), torch.Size([300, 301]), torch.Size([10, 301])]\n",
            "Epoch  0,                 Train:loss=0.121, accuracy=10.5%,                 Valid: loss=0.121, accuracy=10.3%\n",
            "Epoch  1,                 Train:loss=0.019, accuracy=86.4%,                 Valid: loss=0.020, accuracy=85.6%\n",
            "Epoch  2,                 Train:loss=0.017, accuracy=87.7%,                 Valid: loss=0.019, accuracy=86.4%\n",
            "Epoch  3,                 Train:loss=0.015, accuracy=88.7%,                 Valid: loss=0.018, accuracy=86.8%\n",
            "Epoch  4,                 Train:loss=0.015, accuracy=88.8%,                 Valid: loss=0.017, accuracy=86.9%\n",
            "Epoch  5,                 Train:loss=0.014, accuracy=89.8%,                 Valid: loss=0.017, accuracy=87.8%\n",
            "validation accuracy = 0.000\n",
            "------------------------------------------------------------------\n",
            "Training model with a depth of 5 layers and a width of 500 units\n",
            "Teta params=[torch.Size([500, 785]), torch.Size([500, 501]), torch.Size([500, 501]), torch.Size([500, 501]), torch.Size([500, 501]), torch.Size([10, 501])]\n",
            "Epoch  0,                 Train:loss=0.123, accuracy=9.7%,                 Valid: loss=0.123, accuracy=9.3%\n",
            "Epoch  1,                 Train:loss=0.019, accuracy=86.0%,                 Valid: loss=0.021, accuracy=85.2%\n",
            "Epoch  2,                 Train:loss=0.017, accuracy=87.3%,                 Valid: loss=0.019, accuracy=86.4%\n",
            "Epoch  3,                 Train:loss=0.014, accuracy=89.5%,                 Valid: loss=0.017, accuracy=87.8%\n",
            "Epoch  4,                 Train:loss=0.014, accuracy=89.9%,                 Valid: loss=0.017, accuracy=88.1%\n",
            "Epoch  5,                 Train:loss=0.013, accuracy=90.7%,                 Valid: loss=0.016, accuracy=89.3%\n",
            "validation accuracy = 0.000\n",
            "------------------------------------------------------------------\n",
            "Training model with a depth of 5 layers and a width of 1000 units\n",
            "Teta params=[torch.Size([1000, 785]), torch.Size([1000, 1001]), torch.Size([1000, 1001]), torch.Size([1000, 1001]), torch.Size([1000, 1001]), torch.Size([10, 1001])]\n",
            "Epoch  0,                 Train:loss=0.136, accuracy=10.4%,                 Valid: loss=0.135, accuracy=10.9%\n",
            "Epoch  1,                 Train:loss=0.018, accuracy=87.0%,                 Valid: loss=0.019, accuracy=85.7%\n",
            "Epoch  2,                 Train:loss=0.015, accuracy=89.1%,                 Valid: loss=0.017, accuracy=87.7%\n",
            "Epoch  3,                 Train:loss=0.015, accuracy=88.3%,                 Valid: loss=0.018, accuracy=86.6%\n",
            "Epoch  4,                 Train:loss=0.012, accuracy=90.9%,                 Valid: loss=0.015, accuracy=88.4%\n",
            "Epoch  5,                 Train:loss=0.011, accuracy=91.2%,                 Valid: loss=0.015, accuracy=88.5%\n",
            "validation accuracy = 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Tableau pour la précision sur l'ensemble de validation**\n",
        "N.B. que les lignes correspondent aux nombre de couche et les colonnes correspondent au nombre de neurone dans chaque couche. Les valeurs ci-dessous sont donné comme exemples; remplacez-les par les valeurs que vous avez utilisées pour votre recherche d'hyperparamètres.\n",
        "\n",
        "depth\\width  | 25 | 100 | 300 | 500 | 1000\n",
        "-------------------|------------------|------------------|------------------|------------------|------------------|\n",
        "**1**   | -  | - | - | - | - |\n",
        "**3** | -  | - | - | - | - |\n",
        "**5**  | -  | - | - | - | - |"
      ],
      "metadata": {
        "id": "QnDMqFapAUXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD: Analyse du meilleur modèle"
      ],
      "metadata": {
        "id": "2wuN-uw7AUXN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CShZ3VB0AUXN"
      },
      "source": [
        "# SGD\n",
        "# Montrez les résultats pour la meilleure configuration trouvez ci-dessus.\n",
        "depth = None    # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "width = None    # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "lr = None           # Some value\n",
        "batch_size = None   # Some value\n",
        "\n",
        "with torch.no_grad():\n",
        "  data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "  MLP_model = MLPModel(n_features=784, n_hidden_features=width, n_hidden_layers=depth, n_classes=10)\n",
        "  best_model, best_val_accuracy, logger = train(MLP_model,lr=lr, nb_epochs=5, sgd=True,\n",
        "                                                data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "  logger.plot_loss_and_accuracy()\n",
        "  print(f\"Best validation accuracy = {best_val_accuracy*100:.3f}\")\n",
        "\n",
        "  accuracy_test, loss_test = accuracy_and_loss_whole_dataset(data_loader_test, best_model)\n",
        "print(\"Evaluation of the best training model over test set\")\n",
        "print(\"------\")\n",
        "print(f\"Loss : {loss_test:.3f}\")\n",
        "print(f\"Accuracy : {accuracy_test*100.:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adam: Recherche d'hyperparamètres\n",
        "\n",
        "Implémentez Adam, répétez les deux étapes précédentes (recherche d'hyperparamètres et analyse du meilleur modèle) cette fois en utilisat Adam, et comparez les performances finales avec votre meilleur modèle SGD."
      ],
      "metadata": {
        "id": "_tPLgZriAUXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM\n",
        "# Montrez les résultats pour différents nombre de couche, e.g. 1, 3, 5, et différent nombres de neurone, e.g. 25, 100, 300, 500, 1000.\n",
        "depth_list = None   # Define ranges in a list\n",
        "width_list = None   # Define ranges in a list\n",
        "lr = None           # Some value\n",
        "batch_size = None   # Some value\n",
        "\n",
        "with torch.no_grad():\n",
        "  for depth in depth_list:\n",
        "    for width in width_list:\n",
        "      print(\"------------------------------------------------------------------\")\n",
        "      print(\"Training model with a depth of {0} layers and a width of {1} units\".format(depth, width))\n",
        "      data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "      MLP_model = MLPModel(n_features=784, n_hidden_features=width, n_hidden_layers=depth, n_classes=10)\n",
        "      _, val_accuracy, _ = train(MLP_model, lr=lr, nb_epochs=5, sgd=False, data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "      print(f\"validation accuracy = {val_accuracy*100:.3f}\")"
      ],
      "metadata": {
        "id": "tEVOh1r7AUXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Tableau pour la précision sur l'ensemble de validation**\n",
        "N.B. que les lignes correspondent aux nombre de couche et les colonnes correspondent au nombre de neurone dans chaque couche. Les valeurs ci-dessous sont donné comme exemples; remplacez-les par les valeurs que vous avez utilisées pour votre recherche d'hyperparamètres.\n",
        "\n",
        "depth\\width  | 25 | 100 | 300 | 500 | 1000\n",
        "-------------------|------------------|------------------|------------------|------------------|------------------|\n",
        "**1**   | -  | - | - | - | - |\n",
        "**3** | -  | - | - | - | - |\n",
        "**5**  | -  | - | - | - | - |"
      ],
      "metadata": {
        "id": "6LQ6q18CAUXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adam: Analyse du meilleur modèle"
      ],
      "metadata": {
        "id": "df6Y9ziXAUXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM\n",
        "# Montrez les résultats pour la meilleure configuration trouvez ci-dessus.\n",
        "depth = None    # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "width = None    # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "lr = None           # Some value\n",
        "batch_size = None   # Some value\n",
        "\n",
        "with torch.no_grad():\n",
        "  data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "  MLP_model = MLPModel(n_features=784, n_hidden_features=width, n_hidden_layers=depth, n_classes=10)\n",
        "  best_model, best_val_accuracy, logger = train(MLP_model,lr=lr, nb_epochs=5, sgd=False,\n",
        "                                                data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "  logger.plot_loss_and_accuracy()\n",
        "  print(f\"Best validation accuracy = {best_val_accuracy*100:.3f}\")\n",
        "\n",
        "  accuracy_test, loss_test = accuracy_and_loss_whole_dataset(data_loader_test, best_model)\n",
        "print(\"Evaluation of the best training model over test set\")\n",
        "print(\"------\")\n",
        "print(f\"Loss : {loss_test:.3f}\")\n",
        "print(f\"Accuracy : {accuracy_test*100.:.3f}\")"
      ],
      "metadata": {
        "id": "uohnWTtoAUXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyse des Résultats"
      ],
      "metadata": {
        "id": "-wlDcZB-AUXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Répondez içi..."
      ],
      "metadata": {
        "id": "M-Wi3CG3AUXP"
      }
    }
  ]
}