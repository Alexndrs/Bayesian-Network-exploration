{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alexndrs/Bayesian-Network-exploration/blob/main/INF8225_TP1_H25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAHWMYJv4xuc"
      },
      "source": [
        "# INF8225 TP1 H25 (v2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV-6EDgXO-S9"
      },
      "source": [
        "Alexandre - Dréan / 2408681 ########\n",
        "\n",
        "Partie 3 réalisée: [seul(e)]\n",
        "ou avec\n",
        "[Prénom - NOM -\n",
        "Matricule ########]\n",
        "\n",
        "Date limite :\n",
        "\n",
        "20h30 le 6 février 2025 (Partie 1 et 2)\n",
        "\n",
        "20h30 le 20 février 2025 (Partie 3)\n",
        "\n",
        "Remettez votre fichier Colab sur Moodle en 2 formats: **.pdf** ET **.ipynb**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo2CPniBeytl"
      },
      "source": [
        "**Comment utiliser**:\n",
        "\n",
        "Il faut copier ce notebook dans vos dossiers pour avoir une version que vous pouvez modifier, voici deux façons de le faire:\n",
        "* File / Save a copy in Drive ...\n",
        "* File / Download .ipynb\n",
        "\n",
        "**Pour utiliser un GPU**\n",
        "\n",
        "Runtime / Change Runtime Type / Hardware Accelerator / GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCGh-NNm47Tk"
      },
      "source": [
        "# Partie 1 (16 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7tkIgu75Ccd"
      },
      "source": [
        "## Objectif\n",
        "L’objectif de la Partie 1 du travail pratique est de permettre à l’étudiant de se familiariser avec les réseaux Bayésiens et la librairie Numpy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iongVT7XRegv"
      },
      "source": [
        "## Problème\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considérons le réseau Bayésien ci-dessous.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1QCJSfYGLJVg2-0_BO8BEHCnMEDsHSR6k\" alt=\"bayes_net\" width=\"600\"/>\n",
        "\n",
        "Ceci représente un modèle simple pour les notes à un examen (G) et sa relation avec les étudiants qui se préparent aux examens et font correctement le travail pour les devoirs (S), les étudiants qui ont des difficultés dans la vie juste avant l'examen final (D), les étudiants qui réussissent bien à un entretien technique pour un emploi axé sur le sujet du cours (R), et des étudiants qui se retrouvent sur une sorte de palmarès de leur programme (L)."
      ],
      "metadata": {
        "id": "tdKetLE0hVev"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twz4slZ9DY6n"
      },
      "source": [
        "## Trucs et astuces\n",
        "Nous utiliserons des vecteurs multidimensionnels `5d-arrays` dont les `axes` représentent:\n",
        "```\n",
        "axe 0 : Se préparer (S)\n",
        "axe 1 : Difficultés avant l'exam (D)\n",
        "axe 2 : Réussir l'entretien technique (R)\n",
        "axe 3 : Note dans le cours (Grade) (G)\n",
        "axe 4 : Liste d'honneur (L)\n",
        "```\n",
        "\n",
        "Chaque `axe` serait de dimension `2` ou `3`:\n",
        "```\n",
        "Exemple pour S:\n",
        "0 : s0\n",
        "1 : s1\n",
        "\n",
        "Exemple pour G:\n",
        "0 : g0\n",
        "1 : g1\n",
        "2 : g2\n",
        "```\n",
        "Quelques point à garder en tête:\n",
        "- Utiliser la jointe comme point de départ pour vos calculs (ne pas développer tous les termes à la main).\n",
        "- Attention à l'effet du do-operator sur le graphe.\n",
        "- L'argument \"keepdims=True\" de \"np.sum()\" vous permet conserver les mêmes indices.\n",
        "- Pour un rappel sur les probabilités conditionelles, voir: https://www.probabilitycourse.com/chapter1/1_4_0_conditional_probability.php"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUjUNqVcTEXP"
      },
      "source": [
        "## 1. Complétez les tables de probabilités ci-dessous"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-rxnQmCCCPa",
        "outputId": "aaba8f33-0b42-43dc-ff31-25e7f323657a"
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=5)\n",
        "\n",
        "# Les tableaux sont bâtis avec les dimensions (S, D, R, G, L)\n",
        "# et chaque dimension avec les probablités associées aux 2 ou 3 valeurs possibles ({0, 1} ou {0, 1, 2})\n",
        "\n",
        "Pr_S = np.array([0.2, 0.8]).reshape(2, 1, 1, 1, 1) # Donné en exemple\n",
        "Pr_D = np.array([0.9, 0.1]).reshape(1, 2, 1, 1, 1) # TODO\n",
        "Pr_R_given_S = np.array([\n",
        "    [0.9, 0.1],\n",
        "    [0.2, 0.8]\n",
        "]).reshape(2, 1, 2, 1, 1) # TODO\n",
        "Pr_G_given_SD = np.array([\n",
        "    [[0.5, 0.3, 0.2],\n",
        "     [0.9, 0.08, 0.02]],\n",
        "\n",
        "    [[0.1, 0.2, 0.7],\n",
        "     [0.3, 0.4, 0.3]]\n",
        "]).reshape(2, 2, 1, 3, 1) # TODO\n",
        "Pr_L_given_G = np.array([\n",
        "    [0.9, 0.1],\n",
        "    [0.6, 0.4],\n",
        "    [0.01, 0.99]\n",
        "]).reshape(1, 1, 1, 3, 2) # TODO\n",
        "\n",
        "print (f\"Pr(S)=\\n{np.squeeze(Pr_S)}\\n\")\n",
        "print (f\"Pr(D)=\\n{np.squeeze(Pr_D)}\\n\")\n",
        "print (f\"Pr(R|S)=\\n{np.squeeze(Pr_R_given_S)}\\n\")\n",
        "print (f\"Pr(G|S,D)=\\n{np.squeeze(Pr_G_given_SD)}\\n\")\n",
        "print (f\"Pr(L|G)=\\n{np.squeeze(Pr_L_given_G)}\\n\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(S)=\n",
            "[0.2 0.8]\n",
            "\n",
            "Pr(D)=\n",
            "[0.9 0.1]\n",
            "\n",
            "Pr(R|S)=\n",
            "[[0.9 0.1]\n",
            " [0.2 0.8]]\n",
            "\n",
            "Pr(G|S,D)=\n",
            "[[[0.5  0.3  0.2 ]\n",
            "  [0.9  0.08 0.02]]\n",
            "\n",
            " [[0.1  0.2  0.7 ]\n",
            "  [0.3  0.4  0.3 ]]]\n",
            "\n",
            "Pr(L|G)=\n",
            "[[0.9  0.1 ]\n",
            " [0.6  0.4 ]\n",
            " [0.01 0.99]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHD6DX-nS6Qt"
      },
      "source": [
        "## 2. À l'aide de ces tables de probabilité conditionnelles, calculez les requêtes ci-dessous. Dans les cas où l'on compare un calcul non interventionnel à un calcul interventionnel, commentez sur l'interprétation physique des deux situations et les résultats obtenus à partir de vos modèles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-vXI0O279sX"
      },
      "source": [
        "a) $Pr(G) = [P (G = g^0), P (G = g^1), P (G = g^2)]$\n",
        "\n",
        "$P(G) = \\sum_{s,d} P(S=s).P(D=d).P(G|S=s,D=d)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXWtZDsv791d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47074939-ad08-44f1-ee18-376725984631"
      },
      "source": [
        "Pr_G = np.sum(Pr_S * Pr_D * Pr_G_given_SD, axis=(0,1), keepdims=True)\n",
        "\n",
        "answer_a = Pr_G.squeeze() # TODO\n",
        "print(f\"Pr(G)={answer_a}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(G)=[0.204  0.2316 0.5644]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7fla36P79_G"
      },
      "source": [
        "b) $Pr(G|R = r^1)$\n",
        "$P(G|R=r1) = \\frac{P(G,R=r1)}{P(R=r1)} = \\frac{\\sum_{s,d} P(S=s).P(D=d).P(R=r1|S=s).P(G|S=s,D=d)}{\\sum_s P(S=s).P(R=r1|S=s)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Jp2AGLa7-H_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "894c0434-4e4e-41ef-f751-3757b184c373"
      },
      "source": [
        "Pr_GR = np.sum(Pr_S * Pr_D * Pr_R_given_S * Pr_G_given_SD, axis=(0,1), keepdims=True)\n",
        "Pr_R = np.sum(Pr_S * Pr_R_given_S, axis=0, keepdims=True)\n",
        "Pr_G_given_R = Pr_GR / Pr_R\n",
        "\n",
        "answer_b = Pr_G_given_R[:,:,1,:,:].squeeze() # TODO\n",
        "print(f\"Pr(G|R=r1)={answer_b}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(G|R=r1)=[0.13273 0.22176 0.64552]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8mt03aX7-WC"
      },
      "source": [
        "c)  $Pr(G|R = r^0)$\n",
        "\n",
        "pareil qu'au dessus en remplaçant $r^1$ par $r^0$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCxSweb67-dx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "103a8390-102a-4534-9a2c-c63e04202334"
      },
      "source": [
        "answer_c = Pr_G_given_R[:,:,0,:,:].squeeze() # TODO\n",
        "print(f\"Pr(G|R=r0)={answer_c}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(G|R=r0)=[0.34235 0.25071 0.40694]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSK8ulij7-m0"
      },
      "source": [
        "d) $Pr(G|R=r^1, S=s^0)$\n",
        "\n",
        "$P(G|R=r1,S=s0) =\\frac{ P(G,R=r1,S=s0)}{P(R=r1,S=s0)} = \\frac{\\sum_d P(S=s0).P(D=d).P(R=r1|S=s0).P(G|S=s0,D=d)}{P(S=s0).P(R=r1|S=s0)} $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cliFsd8f7-vC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd2f46ef-4e82-48a6-e280-a4b0fd50d78e"
      },
      "source": [
        "Pr_GRS = np.sum(Pr_S * Pr_D * Pr_R_given_S * Pr_G_given_SD, axis=1, keepdims=True)\n",
        "Pr_RS = Pr_S * Pr_R_given_S\n",
        "Pr_G_given_RS = Pr_GRS / Pr_RS\n",
        "\n",
        "answer_d = Pr_G_given_RS[0,:,1,:,:].squeeze() # TODO\n",
        "print(f\"Pr(G|R=r1, S=s0)={answer_d}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(G|R=r1, S=s0)=[0.54  0.278 0.182]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zffAAOW67-5I"
      },
      "source": [
        "e) $Pr(G|R=r^0, S=s^0)$\n",
        "\n",
        "remarque : on va obtenir pareil que pour la question précédente car sous $S$ fixé on a $G$ indépendant de $R$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zyt7TeB7_CD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6818bd-b08c-40bf-d838-f73e62c77c65"
      },
      "source": [
        "answer_e = Pr_G_given_RS[0,:,0,:,:].squeeze() # TODO\n",
        "print(f\"Pr(G|R=r0, S=s0)={answer_e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(G|R=r0, S=s0)=[0.54  0.278 0.182]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeIkZjn47_LZ"
      },
      "source": [
        "f) $Pr(R|D=d^1)$\n",
        "\n",
        "On peut directement dire que $P(R|D=d1) = P(R)$ car R est indépendant de D, on fait quand même le calcule pour le démontrer\n",
        "\n",
        "$P(R|D=d1) = \\sum_s P(R,S=s|D=d1) = sum_s P(R|S=s,D=d1).P(S=s|D=d1) = \\sum_s P(R|S=s).P(S=s) = P(R)$ (car R est indépendant de D selon S fixé et S est indépendant de D)\n",
        "\n",
        "$P(R|D=d1) = P(R)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yscy5bf27_Sq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f29253e-512f-45d0-846a-eb1b517de9fe"
      },
      "source": [
        "\n",
        "\n",
        "answer_f = Pr_R.squeeze() # TODO\n",
        "print(f\"Pr(R|D=d1)={answer_f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|D=d1)=[0.34 0.66]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbV8cFjU8TxQ"
      },
      "source": [
        "g) $Pr(R|D=d^0)$\n",
        "\n",
        "$Pr(R|D=d^0) = Pr(R)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jBgoNDz8T6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c155a56-3168-470c-d65a-4d0a85241e7e"
      },
      "source": [
        "answer_g = Pr_R.squeeze() # TODO\n",
        "print(f\"Pr(R|D=d0)={answer_g}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|D=d0)=[0.34 0.66]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05xm-VaW8UQh"
      },
      "source": [
        "h) $Pr(R|D=d^1, G=g^2)$\n",
        "\n",
        "$P(R|D=d1,G=g2) = \\frac{P(R,D=d1,G=g2)}{P(D=d1,G=g2)} = \\frac{\\sum_s P(S=s).P(D=d1).P(R|S=s).P(G=g2|S=s,D=d1)}{\\sum_s P(S=s).P(D=d1).P(G=g2|S=s,D=d1)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shjD8GIL8UZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4899b9e-928f-40c9-e284-4c6dceb9b8a8"
      },
      "source": [
        "Pr_RDG = np.sum(Pr_S * Pr_D * Pr_R_given_S * Pr_G_given_SD, axis=0, keepdims=True)\n",
        "Pr_DG = np.sum(Pr_S * Pr_D * Pr_G_given_SD, axis=0, keepdims=True)\n",
        "Pr_R_given_DG = Pr_RDG / Pr_DG\n",
        "answer_h = Pr_R_given_DG[:,1,:,2,:].squeeze() # TODO\n",
        "print(f\"Pr(R|D=d1, G=g2)={answer_h}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|D=d1, G=g2)=[0.21148 0.78852]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i2ahKAj8Umu"
      },
      "source": [
        "i) $Pr(R|D=d^0, G=g^2)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nLKd4c18UuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07b1514-b07c-4843-8343-cdf6522614b2"
      },
      "source": [
        "answer_i = Pr_R_given_DG[:,0,:,2,:].squeeze() # TODO\n",
        "print(f\"Pr(R|D=d0, G=g2)={answer_i}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|D=d0, G=g2)=[0.24667 0.75333]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUc0EpO18eA-"
      },
      "source": [
        "j) $Pr(R|D=d^1, L=l^1)$\n",
        "\n",
        "$P(R|D=d1,L=l1) = \\frac{P(R,D=d1,L=l1)}{P(D=d1,L=l1)} = \\frac{\\sum_{s,g} P(S=s).P(D=d1).P(R|S=s).P(G=g|S=s,D=d1).P(L=l1|G=g)}{\\sum_{s,g} P(S=s).P(D=d1).P(G=g|S=s,D=d1).P(L=l1|G=g)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgDLu0nJ8eM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a5db78-7ac5-4470-e477-df8e814b4766"
      },
      "source": [
        "Pr_RDL = np.sum(Pr_S * Pr_D * Pr_R_given_S * Pr_G_given_SD * Pr_L_given_G, axis=(0,3), keepdims=True)\n",
        "Pr_DL = np.sum(Pr_S * Pr_D * Pr_G_given_SD * Pr_L_given_G, axis=(0,3), keepdims=True)\n",
        "Pr_R_given_DL = Pr_RDL / Pr_DL\n",
        "\n",
        "answer_j = Pr_R_given_DL[:,1,:,:,1].squeeze() # TODO\n",
        "print(f\"Pr(R|D=d1, L=l1)={answer_j}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|D=d1, L=l1)=[0.2475 0.7525]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "k) $Pr(R|D=d^0, L=l^1)$\n",
        "\n",
        "On remplace $d^1$ par $d^0$"
      ],
      "metadata": {
        "id": "G2rCcDgyuo5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_k = Pr_R_given_DL[:,0,:,:,1].squeeze() # TODO\n",
        "print(f\"Pr(R|D=d1, L=l1)={answer_k}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpt2RPQqvHbj",
        "outputId": "39778da6-2599-44ae-ed8b-c3b0eb8e8fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|D=d1, L=l1)=[0.2736 0.7264]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "l) $Pr(R|do(G=g^2))$\n",
        "\n",
        "$P(R|do(G=g2)) = P(R)$ car si nous forçons la valeur de $G$ celle ci n'est plus causée par $S$ et donc est $G$ est indépendante de $R$"
      ],
      "metadata": {
        "id": "eiHUsWItvL2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_l = Pr_R.squeeze() # TODO\n",
        "print(f\"Pr(R|do(G=g2))={answer_l}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag5OS3B_vT35",
        "outputId": "0b458670-e97a-4154-ee6b-ad7663f3546e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|do(G=g2))=[0.34 0.66]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "m) $Pr(R|G=g^2)$\n",
        "\n",
        "$P(R|G=g2) = \\sum_s P(R,S=s|G=g2) = \\sum_s P(S=s|G=g2)P(R|S=s,G=g2) = \\sum_s P(S=s|G=g2)P(R|S=s)$\n",
        "Et\n",
        "$P(S=s|G=g2) = \\frac{P(G=g2|S=s)P(S=s)}{P(G=g2)} = \\frac{\\sum_d P(G=g2|S=s,D=d)P(D=d)P(S=s)}{P(G=g2)}$"
      ],
      "metadata": {
        "id": "Dm1JoSs51P6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Pr_S_given_G = np.sum(Pr_G_given_SD * Pr_D * Pr_S, axis=1, keepdims=True) / Pr_G\n",
        "Pr_R_given_G = np.sum(Pr_S_given_G * Pr_R_given_S, axis=0, keepdims=True)\n",
        "\n",
        "answer_m = Pr_R_given_G[:,:,:,2,:].squeeze() # TODO\n",
        "print(f\"Pr(R|G=g2)={answer_m}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lT5Bhwm1Vca",
        "outputId": "d345379d-d610-4271-a363-4df84a015597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R|G=g2)=[0.24515 0.75485]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "n) $Pr(R)$\n",
        "déjà calculer à la question b"
      ],
      "metadata": {
        "id": "2yAntka31ZDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_n = Pr_R.squeeze() # TODO\n",
        "print(f\"Pr(R={answer_n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3156HkiD1mNe",
        "outputId": "b79aa02d-7408-4167-8110-d72d9cca6c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(R=[0.34 0.66]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "o) $Pr(G|do(L=l^1))$\n",
        "\n",
        "Le fait de forcer $L$ à $1$ ne change pas les probabilités de $G$:\n",
        "\n",
        "$P(G|do(L=l1)) = \\sum_{s,d} P(G,S=s,D=d|do(L=l1)) = \\sum_{s,d} P(G,S=s,D=d) = \\sum_{s,d} P(G|S=s,D=d)P(S=s)P(D=d) = P(G) $"
      ],
      "metadata": {
        "id": "wR0NIlpE1dni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_o = Pr_G.squeeze() # TODO\n",
        "print(f\"Pr(G|do(L=l1))={answer_o}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_SfC2CJ1bb7",
        "outputId": "e0ae3c92-b3eb-4a75-fff7-be5660914d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(G|do(L=l1))=[0.204  0.2316 0.5644]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "p) $Pr(G=1|L=l^1)$\n",
        "\n",
        "$P(G=g1|L=l1) = \\frac{P(L=l1|G=g1)P(G=g1)}{P(L=l1)} = \\frac{P(L=l1|G=g1)P(G=g1)}{\\sum_{g} P(L=l1|G=g).P(G=g)}$"
      ],
      "metadata": {
        "id": "Ac48SDKS1x8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Pr_GL = Pr_L_given_G * Pr_G\n",
        "Pr_L = np.sum(Pr_GL, axis=3, keepdims=True)\n",
        "Pr_G_given_L = Pr_GL / Pr_L\n",
        "\n",
        "answer_p = Pr_G_given_L[:,:,:,1,1].squeeze() # TODO\n",
        "print(f\"Pr(G=1|L=l1)={answer_p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dNsTqjJ11P3",
        "outputId": "5dbe9b45-d04a-41cc-eec5-4f9288153026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr(G=1|L=l1)=0.13789900505510602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqfqhDoL5CfA"
      },
      "source": [
        "# Partie 2 (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjIVlyRq5CjA"
      },
      "source": [
        "## Objectif\n",
        "\n",
        "L’objectif de la partie 2 du travail pratique est de permettre à l’étudiant de se familiariser avec l’apprentissage automatique via la régression logistique. Nous allons donc résoudre un problème de classification d'images en utilisant l’approche de descente du gradient (gradient descent) pour optimiser la log-vraisemblance négative (negative log-likelihood) comme fonction de perte.\n",
        "\n",
        "L'algorithme à implémenter est une variation de descente de gradient qui s’appelle l’algorithme de descente de gradient stochastique par mini-ensemble (mini-batch stochastic gradient descent).  Votre objectif est d’écrire un programme en Python pour optimiser les paramètres d’un modèle étant donné un ensemble de données d’apprentissage, en utilisant un ensemble de validation pour déterminer quand arrêter l'optimisation, et finalement de montrer la performance sur l’ensemble du test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFxYYRQJ5Cnb"
      },
      "source": [
        "## Théorie: la régression logistique et le calcul du gradient\n",
        "\n",
        "\n",
        "Il est possible d’encoder l’information concernant l’étiquetage avec des vecteurs multinomiaux (one-hot vectors), c.-à-d. un vecteur de zéros avec un seul 1 pour indiquer quand la classe $C=k$ dans la dimension $k$. Par exemple, le vecteur $\\mathbf{y}=[0, 1, 0, \\cdots, 0]^T$ représente la deuxième classe. Les caractéristiques (features) sont données par des vecteurs $\\mathbf{x}_i \\in \\mathbb{R}^{D}$. En définissant les paramètres de notre modèle comme : $\\mathbf{W}=[\\mathbf{w}_1, \\cdots, \\mathbf{w}_K]^T$ et $\\mathbf{b}=[b_1, b_2, \\cdots  b_K]^T$ et la fonction softmax comme fonction de sortie, on peut exprimer notre modèle sous la forme :\n",
        "\\begin{eqnarray}\n",
        "    p(\\mathbf{y}|\\mathbf{x})\n",
        "    &=& \\frac{\\exp(\\mathbf{y}^T \\mathbf{W} \\mathbf{x} + \\mathbf{y}^T \\mathbf{b})}{\\sum_{\\mathbf{y}_k \\in \\mathscr{Y}} \\exp(\\mathbf{y}_k^T \\mathbf{W} \\mathbf{x} + \\mathbf{y}_k^T \\mathbf{b})}\n",
        "\\end{eqnarray}\n",
        "L'ensemble de données consiste de $n$ paires (label, input) de la forme $\\mathscr{D}:=(\\mathbf{\\tilde{y}}_i, \\mathbf{\\tilde{x}}_i)_{i=1}^n$, où nous utilisons l'astuce de redéfinir $\\mathbf{\\tilde{x}}_i = [\\mathbf{\\tilde{x}}_i^T 1]^T$ et nous redéfinissions la matrice de paramètres $\\boldsymbol{\\theta} \\in \\mathbb{R}^{K\\times(D+1)}$ (voir des notes de cours pour la relation entre $\\boldsymbol{\\theta}$ et $\\mathbf{W}$). Notre fonction de perte, la log-vraisemblance négative des données selon notre modèle est définie comme:\n",
        "\\begin{equation}\n",
        "    \\mathscr{L}\\big( \\boldsymbol{\\theta}, \\mathscr{D} \\big) := -\\log \\prod_{i=1}^N P(\\mathbf{\\tilde{y}}_i|\\mathbf{\\tilde{x}}_i; \\boldsymbol{\\theta})\n",
        "\\end{equation}\n",
        "Pour cette partie du TP, nous avons calculé pour vous le gradient de la fonction de perte par rapport par rapport aux paramètres du modèle:\n",
        "\\begin{eqnarray}\n",
        "    \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\mathscr{L}\\big( \\boldsymbol{\\theta}, \\mathscr{D} \\big)\n",
        "    &=& -\\sum_{i=1}^N \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\Bigg\\{\\log \\Bigg(\\frac{\\exp(\\mathbf{\\tilde{y}}_i^T \\boldsymbol{\\theta} \\mathbf{\\tilde{x}}_i)}{\\sum_{\\mathbf{y}_k \\in \\mathscr{Y}} \\exp(\\mathbf{y}_k^T \\boldsymbol{\\theta} \\mathbf{\\tilde{x}}_i)} \\Bigg) \\Bigg\\} \\\\\n",
        "    &=& -\\sum_{i=1}^N \\left(\\mathbf{\\tilde{y}}_i \\mathbf{\\tilde{x}}^T_i- \\sum_{\\mathbf{y}_k \\in \\mathscr{Y}} P(\\mathbf{y}_k|\\mathbf{\\tilde{x}}_i,\\boldsymbol{\\theta}) \\mathbf{y}_k \\mathbf{\\tilde{x}}^T_i \\right) \\\\\n",
        "    &=& \\sum_{i=1}^N \\mathbf{\\hat{p}}_i \\mathbf{\\tilde{x}}^T_i - \\sum_{i=1}^N \\mathbf{\\tilde{y}}_i \\mathbf{\\tilde{x}}^T_i\n",
        "\\end{eqnarray}\n",
        "où $\\mathbf{\\hat{p}}_i$ est un vecteur de probabilités produit par le modèle pour l'exemple $\\mathbf{\\tilde{x}}_i$ et $\\mathbf{\\tilde{y}}_i$ est le vrai *label* pour ce même exemple.\n",
        "\n",
        "Finalement, il reste à discuter de l'évaluation du modèle. Pour la tâche d'intérêt, qui est une instance du problème de classification, il existe plusieurs métriques pour mesurer les performances du modèle la précision de classification, l'erreur de classification, le taux de faux/vrai positifs/négatifs, etc. Habituellement dans le contexte de l'apprentissage automatique, la précision est la plus commune.\n",
        "\n",
        "La précision est définie comme le rapport du nombre d'échantillons bien classés sur le nombre total d'échantillons à classer:\n",
        "$$\n",
        "\\tau_{acc} := \\frac{|\\mathscr{C}|}{|\\mathscr{D}|}\n",
        "$$\n",
        "où l'ensemble des échantillons bien classés $\\mathscr{C}$ est:\n",
        "$$\n",
        "\\mathscr{C} := \\lbrace (\\mathbf{x}, \\mathbf{y}) \\in \\mathscr{D} \\, | \\, \\underset{k}{\\arg\\max} \\, \\, P(\\cdot|\\mathbf{\\tilde{x}}_i; \\boldsymbol{\\theta})_k = \\underset{k}{\\arg\\max} \\, \\, \\tilde{y}_{i,k} \\rbrace\n",
        "$$\n",
        "En mots, il s'agit du sous-ensemble d'échantillons pour lesquels la classe la plus probable selon notre modèle correspond à la vraie classe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffr5uSLRzkkY"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3wjjnIDGHZj"
      },
      "source": [
        "## Description des tâches\n",
        "\n",
        "#### 1. Code à compléter\n",
        "\n",
        "On vous demande de compléter l'extrait de code ci-dessous pour résoudre ce problème. Vous devez utiliser la librairie PyTorch cette partie du TP: https://pytorch.org/docs/stable/index.html. Mettez à jour les paramètres de votre modèle avec la descente par *mini-batch*. Exécutez des expériences avec trois différents ensembles: un ensemble d’apprentissages avec 90\\% des exemples (choisis au hasard), un ensemble de validation avec 10\\%. Utilisez uniquement l'ensemble de test pour obtenir votre meilleur résultat une fois que vous pensez avoir obtenu votre meilleure stratégie pour entraîner le modèle.\n",
        "\n",
        "#### 2. Rapport à rédiger\n",
        "\n",
        "Présentez vos résultats dans un rapport. Ce rapport devrait inclure:\n",
        "\n",
        "- **Recherche d'hyperparamètres:** Faites une recherche d'hyperparamètres pour différents taux d'apprentissage, e.g. 0.1, 0.01, 0.001, et différentes tailles de mini-batch, e.g. 1, 20, 200, 1000 pour des modèles entrainés avec SGD. Présentez dans un tableau la précision finale du modèle, sur l'*ensemble de validation*, pour ces différentes combinaisons d'hyperparamètres.\n",
        "\n",
        "- **Analyse du meilleur modèle:** Pour votre meilleur modèle, présentez deux figures montrant la progression de son apprentissage sur l'*ensembe d'entrainement et l'ensemble de validation*. La première figure montrant les courbes de log-vraisemblance négative moyenne après chaque epoch, la deuxième montrant la précision du modèle après chaque epoch. Finalement donnez la précision finale sur l'ensemble de test.\n",
        "\n",
        "- **Lire l'article de recherche -\n",
        "Adam**: a method for stochastic optimization. Kingma, D., \\& Ba, J. (2015). International Conference on Learning Representation (ICLR).\n",
        "https://arxiv.org/pdf/1412.6980.pdf. Implémentez Adam, répétez les deux étapes précédentes (recherche d'hyperparamètres et analyse du meilleur modèle) cette fois en utilisat Adam, et comparez les performances finales avec votre meilleur modèle SGD.\n",
        "\n",
        "**IMPORTANT**\n",
        "\n",
        "L'objectif du TP est de vous faire implémenter la rétropropagation à la main. **Il est donc interdit d'utiliser les capacités de construction de modèles ou de différentiation automatique de pytorch -- par exemple, aucun appels à torch.nn, torch.autograd ou à la méthode .backward().** L'objectif est d'implémenter un modèle de classification logistique ainsi que son entainement en utilisant uniquement des opérations matricielles de base fournies par PyTorch e.g. torch.sum(), torch.matmul(), etc."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fonctions fournies"
      ],
      "metadata": {
        "id": "oQq0nDgZuMfs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U_jhXT_0Cbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c69a911e-f4fb-45b7-f64e-f9cc63823027"
      },
      "source": [
        "# fonctions pour charger les ensembles de donnees\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=1):\n",
        "  dataset = FashionMNIST(\"./dataset\", train=True,  download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "  dataset_test = FashionMNIST(\"./dataset\", train=False,  download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "  len_train = int(len(dataset) * (1.-val_percentage))\n",
        "  len_val = len(dataset) - len_train\n",
        "  dataset_train, dataset_val = random_split(dataset, [len_train, len_val])\n",
        "  data_loader_train = DataLoader(dataset_train, batch_size=batch_size,shuffle=True,num_workers=4)\n",
        "  data_loader_val   = DataLoader(dataset_val, batch_size=batch_size,shuffle=True,num_workers=4)\n",
        "  data_loader_test  = DataLoader(dataset_test, batch_size=batch_size,shuffle=True,num_workers=4)\n",
        "  return data_loader_train, data_loader_val, data_loader_test\n",
        "\n",
        "def reshape_input(x, y):\n",
        "    x = x.view(-1, 784)\n",
        "    y = torch.FloatTensor(len(y), 10).zero_().scatter_(1,y.view(-1,1),1)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "# call this once first to download the datasets\n",
        "_ = get_fashion_mnist_dataloaders()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 213kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.90MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 4.82MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H5BnbgAOpio"
      },
      "source": [
        "# simple logger to track progress during training\n",
        "class Logger:\n",
        "    def __init__(self):\n",
        "        self.losses_train = []\n",
        "        self.losses_valid = []\n",
        "        self.accuracies_train = []\n",
        "        self.accuracies_valid = []\n",
        "\n",
        "    def log(self, accuracy_train=0, loss_train=0, accuracy_valid=0, loss_valid=0):\n",
        "        self.losses_train.append(loss_train)\n",
        "        self.accuracies_train.append(accuracy_train)\n",
        "        self.losses_valid.append(loss_valid)\n",
        "        self.accuracies_valid.append(accuracy_valid)\n",
        "\n",
        "    def plot_loss_and_accuracy(self, train=True, valid=True):\n",
        "\n",
        "        assert train and valid, \"Cannot plot accuracy because neither train nor valid.\"\n",
        "\n",
        "        figure, (ax1, ax2) = plt.subplots(nrows=1, ncols=2,\n",
        "                                            figsize=(12, 6))\n",
        "\n",
        "        if train:\n",
        "            ax1.plot(self.losses_train, label=\"Training\")\n",
        "            ax2.plot(self.accuracies_train, label=\"Training\")\n",
        "        if valid:\n",
        "            ax1.plot(self.losses_valid, label=\"Validation\")\n",
        "            ax1.set_title(\"CrossEntropy Loss\")\n",
        "            ax2.plot(self.accuracies_valid, label=\"Validation\")\n",
        "            ax2.set_title(\"Accuracy\")\n",
        "\n",
        "        for ax in figure.axes:\n",
        "            ax.set_xlabel(\"Epoch\")\n",
        "            ax.legend(loc='best')\n",
        "            ax.set_axisbelow(True)\n",
        "            ax.minorticks_on()\n",
        "            ax.grid(True, which=\"major\", linestyle='-')\n",
        "            ax.grid(True, which=\"minor\", linestyle='--', color='lightgrey', alpha=.4)\n",
        "\n",
        "    def print_last(self):\n",
        "        print(f\"Epoch {len(self.losses_train):2d}, \\\n",
        "                Train:loss={self.losses_train[-1]:.3f}, accuracy={self.accuracies_train[-1]*100:.1f}%, \\\n",
        "                Valid: loss={self.losses_valid[-1]:.3f}, accuracy={self.losses_valid[-1]*100:.1f}%\", flush=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAJ5iiRUZw3f"
      },
      "source": [
        "## Aperçu de l'ensemble de données FashionMnist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "fK-eNmc8Zv2d",
        "outputId": "8b5f000b-0a6a-4073-b9d0-c69a7dbf110b"
      },
      "source": [
        "def plot_samples():\n",
        "  a, _, _ = get_fashion_mnist_dataloaders()\n",
        "  num_row = 2\n",
        "  num_col = 5# plot images\n",
        "  num_images = num_row * num_col\n",
        "  fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
        "  for i, (x,y) in enumerate(a):\n",
        "      if i >= num_images:\n",
        "        break\n",
        "      ax = axes[i//num_col, i%num_col]\n",
        "      x = (x.numpy().squeeze() * 255).astype(int)\n",
        "      y = y.numpy()[0]\n",
        "      ax.imshow(x, cmap='gray')\n",
        "      ax.set_title(f\"Label: {y}\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "plot_samples()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 750x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpZ8NK8_CAqW"
      },
      "source": [
        "## Fonctions à compléter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        " ***Crossentropy***\n",
        "\n",
        "Pour un vecteur one-hot $y$ et la prédiction (distrib de proba prédites) $y_{pred}$ on a l'erreur de cross entropy\n",
        "\n",
        "$-\\sum_{c=1}^K y_c \\log(y_{pred,c})$\n",
        "Donc pour avoir la loss sur un batch entier on fait la moyenne\n",
        "$-\\frac{1}{len(Batch)}\\sum_{i\\in Batch}\\sum_{c=1}^K y_c \\log(y_{pred,c})$\n"
      ],
      "metadata": {
        "id": "DXug6tGWUZrr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSc19WnyQsFv"
      },
      "source": [
        "def accuracy(y, y_pred) :\n",
        "    # todo : nombre d'éléments à classifier.\n",
        "    card_D = len(y)\n",
        "\n",
        "    # todo : calcul du nombre d'éléments bien classifiés.\n",
        "    y_pred_classes = torch.argmax(y_pred, dim=1)  # Indices des classes prédictes\n",
        "    y_true_classes = torch.argmax(y, dim=1)       # Indices des classes vraies\n",
        "    card_C = (y_pred_classes == y_true_classes).sum().item()\n",
        "\n",
        "    # todo : calcul de la précision de classification.\n",
        "    acc = card_C / card_D\n",
        "\n",
        "    return acc, (card_C, card_D)\n",
        "\n",
        "def accuracy_and_loss_whole_dataset(data_loader, model):\n",
        "    cardinal = 0\n",
        "    loss     = 0.\n",
        "    n_accurate_preds  = 0.\n",
        "\n",
        "    for x, y in data_loader:\n",
        "        x, y = reshape_input(x, y)\n",
        "        y_pred                = model.forward(x)\n",
        "        xentrp                = cross_entropy(y, y_pred)\n",
        "        _, (n_acc, n_samples) = accuracy(y, y_pred)\n",
        "\n",
        "        cardinal = cardinal + n_samples\n",
        "        loss     = loss + xentrp\n",
        "        n_accurate_preds  = n_accurate_preds + n_acc\n",
        "\n",
        "    loss = loss / float(cardinal)\n",
        "    acc  = n_accurate_preds / float(cardinal)\n",
        "\n",
        "    return acc, loss\n",
        "\n",
        "def cross_entropy(y, y_pred):\n",
        "    # todo : calcul de la valeur d'entropie croisée.\n",
        "    loss = -torch.sum(y * torch.log(y_pred + 1e-8)) / y.shape[0]\n",
        "    return loss\n",
        "\n",
        "def softmax(x, axis=-1):\n",
        "    # assurez vous que la fonction est numeriquement stable\n",
        "    # e.g. a\n",
        "    # todo : calcul des valeurs de softmax(x)\n",
        "\n",
        "    #On assume que les d'entrées sont les suivantes :\n",
        "\n",
        "    # x = [x_1, x_2 ... x_batchSize]\n",
        "    # x_1 = [w_observ1_classe0 . x_observ1_classe0 + b_observ1_classe0, w_observ1_classe1 . x_observ1_classe1 + b_observ1_classe1, ...]  (logit pour les différentes classes)\n",
        "\n",
        "    # Pour la stabilité comme softmax(x_i) = [exp(x_i[0]), exp(x_i[1]), ... , exp(x_i[K])] / sum(exp(x_i))\n",
        "    # si on divise en haut et en base bar exp(max(x_i)) on toujours l'égalité donc on peut juste retranché le logit le plus grand pour chaque batch afin d'avoir aucun exponentiel > 1 (non stable) à caculer\n",
        "\n",
        "    x_max = torch.amax(x, dim=axis, keepdim=True)\n",
        "    x_exp = torch.exp(x - x_max)\n",
        "    sum_exp = torch.sum(x_exp, dim=axis, keepdim=True)\n",
        "    values = x_exp / sum_exp\n",
        "    return values\n",
        "\n",
        "def inputs_tilde(x, axis=-1):\n",
        "    # augments the inputs `x` with ones along `axis`\n",
        "    # todo : implémenter code ici.\n",
        "    # On concatène une colonne de 1 pour le biais\n",
        "    ones = torch.ones(x.shape[0], 1)\n",
        "    x_tilde = torch.cat((x, ones), dim=axis)\n",
        "    return x_tilde"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax(torch.tensor([[1000, 10000, 100000]]), axis =1)\n",
        "# La stabilité est assurée et on a bien le résultat attentue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMj6mPPoz4jR",
        "outputId": "c676be79-5baa-4bc1-8404-dae50fe2c654"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya7J-i89GHnp"
      },
      "source": [
        "class LinearModel:\n",
        "    def __init__(self, num_features, num_classes):\n",
        "      self.params = torch.normal(0, 0.01, (num_features + 1, num_classes))\n",
        "\n",
        "      self.t = 0\n",
        "      self.m_t = 0 # pour Adam: moyennes mobiles du gradient\n",
        "      self.v_t = 0 # pour Adam: moyennes mobiles du carré du gradient\n",
        "\n",
        "    def forward(self, x):\n",
        "      # todo : implémenter calcul des outputs en fonction des inputs `x`.\n",
        "\n",
        "      # Pour un batch de taille batchSize on a les dimensions suivantes :\n",
        "      # x                   : (batchSize, 784)\n",
        "      # inputs_tilde(x,1)   : (batchSize, 785)\n",
        "      # self.params (W)     : (785, 10)\n",
        "\n",
        "      # On veut des logits de dimension (batchSize, 10), il faut donc faire la multiplication matricielle\n",
        "      # logits = inputs_tilde(x,1) * self.params  (= x_augmented * W contrairement à w.x^T écris dans le cours)\n",
        "\n",
        "\n",
        "      inputs = inputs_tilde(x, 1)\n",
        "      logits = torch.matmul(inputs, self.params)\n",
        "      outputs = softmax(logits)\n",
        "      return outputs\n",
        "\n",
        "    def get_grads(self, y, y_pred, X):\n",
        "      # todo : implémenter calcul des gradients.\n",
        "\n",
        "      # On veut un gradient de la même dimension que W (self.params) i.e (785,10)\n",
        "      #\n",
        "      # On a les entrées de dimensions\n",
        "      # inputs_tilde(X,1) : (batchSize,785)\n",
        "      # y : (batchSize,10)\n",
        "      # y_pred : (batchSize, 10)\n",
        "      #\n",
        "      # Le gradient ce calcule donc comme\n",
        "      # inputs_tilde(X,1)^T * (y_pred - y)\n",
        "\n",
        "      grads = torch.matmul(torch.transpose(inputs_tilde(X, 1), 0, 1), (y_pred - y))\n",
        "      return grads\n",
        "\n",
        "    def sgd_update(self, lr, grads):\n",
        "      # TODO : implémenter mise à jour des paramètres ici.\n",
        "      self.params -= lr * grads\n",
        "\n",
        "    def adam_update(self, lr, grads):\n",
        "      # TODO : implémenter mise à jour des paramètres ici.\n",
        "      pass\n",
        "\n",
        "def train(model, lr=0.1, nb_epochs=10, sgd=True, data_loader_train=None, data_loader_val=None):\n",
        "    best_model = None\n",
        "    best_val_accuracy = 0\n",
        "    logger = Logger()\n",
        "\n",
        "    for epoch in range(nb_epochs+1):\n",
        "        # at epoch 0 evaluate random initial model\n",
        "        #   then for subsequent epochs, do optimize before evaluation.\n",
        "        if epoch > 0:\n",
        "          for x, y in data_loader_train:\n",
        "              x, y = reshape_input(x, y)\n",
        "              y_pred = model.forward(x)\n",
        "              loss = cross_entropy(y, y_pred)\n",
        "              grads = model.get_grads(y, y_pred, x)\n",
        "              if sgd:\n",
        "                model.sgd_update(lr, grads)\n",
        "              else:\n",
        "                model.adam_update(lr, grads)\n",
        "\n",
        "        accuracy_train, loss_train = accuracy_and_loss_whole_dataset(data_loader_train, model)\n",
        "        accuracy_val, loss_val = accuracy_and_loss_whole_dataset(data_loader_val, model)\n",
        "\n",
        "        if accuracy_val > best_val_accuracy:\n",
        "          best_val_accuracy = accuracy_val\n",
        "          best_model = model\n",
        "\n",
        "        logger.log(accuracy_train, loss_train, accuracy_val, loss_val)\n",
        "        print(f\"Epoch {epoch:2d}, \\\n",
        "                Train: loss={loss_train:.3f}, accuracy={accuracy_train*100:.1f}%, \\\n",
        "                Valid: loss={loss_val:.3f}, accuracy={accuracy_val*100:.1f}%\", flush=True)\n",
        "\n",
        "    return best_model, best_val_accuracy, logger\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Évaluation"
      ],
      "metadata": {
        "id": "_zUGBmtf9pcA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD: Recherche d'hyperparamètres"
      ],
      "metadata": {
        "id": "eUuU5n979pcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD\n",
        "# Montrez les résultats pour différents taux d'apprentissage, e.g. 0.1, 0.01, 0.001, et différentes tailles de mini-batch, e.g. 1, 20, 200, 1000.\n",
        "batch_size_list = [1, 20, 200, 1000]   # Define ranges in a list\n",
        "lr_list = [0.1, 0.01, 0.001]           # Define ranges in a list\n",
        "\n",
        "with torch.no_grad():\n",
        "  for lr in lr_list:\n",
        "    for batch_size in batch_size_list:\n",
        "      print(\"------------------------------------------------------------------\")\n",
        "      print(\"Training model with a learning rate of {0} and a batch size of {1}\".format(lr, batch_size))\n",
        "      data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "      model = LinearModel(num_features=784, num_classes=10)\n",
        "      _, val_accuracy, _ = train(model,lr=lr, nb_epochs=5, sgd=True, data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "      print(f\"validation accuracy = {val_accuracy*100:.3f}\")"
      ],
      "metadata": {
        "id": "4R_6Rxgq9pcE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c00231f-f886-4e89-eeee-ba8d1d5f8690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------\n",
            "Training model with a learning rate of 0.1 and a batch size of 1\n",
            "Epoch  0,                 Train: loss=2.327, accuracy=3.1%,                 Valid: loss=2.328, accuracy=3.0%\n",
            "Epoch  1,                 Train: loss=2.329, accuracy=80.1%,                 Valid: loss=2.346, accuracy=80.2%\n",
            "Epoch  2,                 Train: loss=1.926, accuracy=81.8%,                 Valid: loss=1.974, accuracy=81.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Tableau pour la précision sur l'ensemble de validation**\n",
        "N.B. que les lignes correspondent aux valeurs du taux d'apprentisage et les colonnes correspondent au valeur du batch size. Les valeurs ci-dessous sont donné comme exemples; remplacez-les par les valeurs que vous avez utilisées pour votre recherche d'hyperparamètres.\n",
        "\n",
        "learning rate\\batch_size  | 1 | 20 | 200 | 1000\n",
        "-------------------|------------------|------------------|------------------|------------------|\n",
        "**0.1**   | -  | - | - | - | - |\n",
        "**0.01** | -  | - | - | - | - |\n",
        "**0.001**  | -  | - | - | - | - |"
      ],
      "metadata": {
        "id": "AmvtxoLo9pcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD: Analyse du meilleur modèle"
      ],
      "metadata": {
        "id": "8PvrqlWt9pcG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ8Vc8JM9pcG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "47831234-2f82-4c10-e4f0-d287591cb5bf"
      },
      "source": [
        "# SGD\n",
        "# Montrez les résultats pour la meilleure configuration trouvez ci-dessus.\n",
        "batch_size = None # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "lr = None         # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "\n",
        "with torch.no_grad():\n",
        "  data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "  model = LinearModel(num_features=784, num_classes=10)\n",
        "  best_model, best_val_accuracy, logger = train(model,lr=lr, nb_epochs=5, sgd=True,\n",
        "                                                data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "  logger.plot_loss_and_accuracy()\n",
        "  print(f\"Best validation accuracy = {best_val_accuracy*100:.3f}\")\n",
        "\n",
        "  accuracy_test, loss_test = accuracy_and_loss_whole_dataset(data_loader_test, best_model)\n",
        "print(\"Evaluation of the best training model over test set\")\n",
        "print(\"------\")\n",
        "print(f\"Loss : {loss_test:.3f}\")\n",
        "print(f\"Accuracy : {accuracy_test*100.:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'int' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-686ab4a40549>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   best_model, best_val_accuracy, logger = train(model,lr=lr, nb_epochs=5, sgd=True,\n\u001b[0m\u001b[1;32m     11\u001b[0m                                                 data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n\u001b[1;32m     12\u001b[0m   \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_loss_and_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e7d1fe8e9e8c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, lr, nb_epochs, sgd, data_loader_train, data_loader_val)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madam_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0maccuracy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_and_loss_whole_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0maccuracy_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_and_loss_whole_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6bffc643ff96>\u001b[0m in \u001b[0;36maccuracy_and_loss_whole_dataset\u001b[0;34m(data_loader, model)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0my_pred\u001b[0m                \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mxentrp\u001b[0m                \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-e6aa63cbbe69>\u001b[0m in \u001b[0;36mreshape_input\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreshape_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adam: Recherche d'hyperparamètres\n",
        "\n",
        "Implémentez Adam, répétez les deux étapes précédentes (recherche d'hyperparamètres et analyse du meilleur modèle) cette fois en utilisat Adam, et comparez les performances finales avec votre meilleur modèle SGD."
      ],
      "metadata": {
        "id": "BOZXfA919pcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM\n",
        "# Montrez les résultats pour différents taux d'apprentissage, e.g. 0.1, 0.01, 0.001, et différentes tailles de mini-batch, e.g. 1, 20, 200, 1000.\n",
        "batch_size_list = None   # Define ranges in a list\n",
        "lr_list = None           # Define ranges in a list\n",
        "\n",
        "with torch.no_grad():\n",
        "  for lr in lr_list:\n",
        "    for batch_size in batch_size_list:\n",
        "      print(\"------------------------------------------------------------------\")\n",
        "      print(\"Training model with a learning rate of {0} and a batch size of {1}\".format(lr, batch_size))\n",
        "      data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "      model = LinearModel(num_features=784, num_classes=10)\n",
        "      _, val_accuracy, _ = train(model,lr=lr, nb_epochs=5, sgd=False, data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "      print(f\"validation accuracy = {val_accuracy*100:.3f}\")"
      ],
      "metadata": {
        "id": "Ze9D0Zpi9pcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Tableau pour la précision sur l'ensemble de validation**\n",
        "N.B. que les lignes correspondent aux valeurs du taux d'apprentisage et les colonnes correspondent au valeur du batch size. Les valeurs ci-dessous sont donné comme exemples; remplacez-les par les valeurs que vous avez utilisées pour votre recherche d'hyperparamètres.\n",
        "\n",
        "learning rate\\batch_size  | 1 | 20 | 200 | 1000\n",
        "-------------------|------------------|------------------|------------------|------------------|\n",
        "**0.1**   | -  | - | - | - | - |\n",
        "**0.01** | -  | - | - | - | - |\n",
        "**0.001**  | -  | - | - | - | - |"
      ],
      "metadata": {
        "id": "Cr9_MzpX_CvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adam: Analyse du meilleur modèle"
      ],
      "metadata": {
        "id": "2Me7IOblUrYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM\n",
        "# Montrez les résultats pour la meilleure configuration trouvez ci-dessus.\n",
        "batch_size = None # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "lr = None         # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "\n",
        "with torch.no_grad():\n",
        "  data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "  model = LinearModel(num_features=784, num_classes=10)\n",
        "  best_model, best_val_accuracy, logger = train(model,lr=lr, nb_epochs=5, sgd=False,\n",
        "                                                data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "  logger.plot_loss_and_accuracy()\n",
        "  print(f\"Best validation accuracy = {best_val_accuracy*100:.3f}\")\n",
        "\n",
        "  accuracy_test, loss_test = accuracy_and_loss_whole_dataset(data_loader_test, best_model)\n",
        "print(\"Evaluation of the best training model over test set\")\n",
        "print(\"------\")\n",
        "print(f\"Loss : {loss_test:.3f}\")\n",
        "print(f\"Accuracy : {accuracy_test*100.:.3f}\")"
      ],
      "metadata": {
        "id": "Ndf_GP6XPV-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyse des Résultats"
      ],
      "metadata": {
        "id": "6LRkxtUD_RVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Répondez içi..."
      ],
      "metadata": {
        "id": "8NIRJe-8_fbP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IficnxEMMcNo"
      },
      "source": [
        "# Partie 3 (20 points)\n",
        "\n",
        "Pour cette partie, vous pouvez travailler en groupes de 2, mais il faut écrire sa propre dérivation et soumettre son propre rapport. Si vous travaillez avec un partenaire, il faut indiquer leur nom dans votre rapport."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zmb_putke8pl"
      },
      "source": [
        "### Problème"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRioLmIDMcP8"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=17_N7pIrf5pypQKiUh5cM7SX6raZUBcJC)\n",
        "\n",
        "Considérons maintenant un réseau de neurones avec une couche d'entrée avec $D=784$ unités, $L$ couches cachées, chacune avec 300 unités et un vecteur de sortie $\\mathbf{y}$ de dimension $K$. Vous avez $i = 1, .., N$ exemples dans un ensemble d'apprentissage, où chaque ${\\bf x}_i \\in \\mathbb{R}^{784}$ est un vecteur de caractéristiques (features). $\\mathbf{y}$ est un vecteur du type *one-hot* -- un vecteur de zéros avec un seul 1 pour indiquer que la classe $C=k$ dans la dimension $k$. Par exemple, le vecteur $\\mathbf{y}=[0, 1, 0, \\cdots, 0]^T$ représente la deuxième classe. La fonction de perte est donnée par\n",
        "\\begin{equation}\n",
        "\\mathscr{L} = -\\sum_{i=1}^{N}\\sum_{k=1}^{K}y_{k,i}\\log (f_k( {\\bf x}_i )  )\n",
        "\\end{equation}\n",
        "\n",
        "La fonction d'activation de la couche finale a la forme  ${\\bf f} = [f_1, ..., f_K]$ donné par la fonction d'activation softmax:\n",
        "\\begin{equation}\n",
        "f_k( {\\bf a}^{(L+1)}({\\bf x}_i) ) = \\frac{\\exp(a_k^{(L+1)})}{\\sum_{c=1}^{K}\\exp(a_c^{(L+1)})}, \\;\\;\\;\\;\n",
        "\\nonumber\n",
        "\\end{equation}\n",
        "\n",
        "et les couches cachées utilisent une fonction d'activation de type ReLU:\n",
        "\\begin{equation}\n",
        "  {\\bf h}^{(l)}({\\bf a}^{(l)}({\\bf x}_i)) = \\text{ReLU}({\\bf a}^{(l)}({\\bf x}_i) = \\max\\Big(0, \\, \\, {\\bf a}^{(l)}({\\bf x}_i)\\Big)\n",
        "\\end{equation}\n",
        "\n",
        "où ${\\bf a}^{(l)}$ est le vecteur résultant du calcul de la préactivation habituelle ${\\bf a}^{(l)}={\\bf W}^{(l)}{\\bf h}^{(l-1)} + {\\bf b}^{(l)}$, qui pourrait être simplifiée à ${\\boldsymbol \\theta}^{(l)}\\tilde{\\bf h}^{(l-1)}$ en utilisant l'astuce de définir $\\tilde{\\bf h}$ comme ${\\bf h}$ avec un 1 concaténé à la fin du vecteur.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzMpz3Zse0t9"
      },
      "source": [
        "### Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK8gnygxMcSh"
      },
      "source": [
        "* a) (10 points) Donnez le pseudocode incluant des *calculs matriciels—vectoriels* détaillés pour l'algorithme de rétropropagation pour calculer le gradient pour les paramètres de chaque couche **étant donné un exemple d'entraînement**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y431_w4gMcX2"
      },
      "source": [
        "* b) (15 points)\n",
        "Implémentez l'optimisation basée sur le gradient de ce réseau en Pytorch.\n",
        "Utilisez le code squelette ci-dessous comme point de départ et implémentez les mathématiques de l'algorithme de rétropropagation que vous avez décrit à la question précédente. Comparez vos gradients et votre optimisation avec le même modèle optimisé avec Autograd. Lequel est le plus rapide ? Proposez quelques expériences. Utilisez encore l'ensemble de données de Fashion MNIST (voir Partie 2). **Comparez différents modèles ayant différentes largeurs (nombre d'unités) et profondeurs (nombre de couches)**. Ici encore, n'utilisez l'ensemble de test que pour votre expérience finale lorsque vous pensez avoir obtenu votre meilleur modèle.\n",
        "\n",
        "\n",
        "**IMPORTANT**\n",
        "\n",
        "L'objectif du TP est de vous faire implémenter la rétropropagation à la main. L'objectif est d'implémenter un modèle de classification logistique ainsi que son entainement en utilisant uniquement des opérations matricielles de base fournies par PyTorch e.g. torch.sum(), torch.matmul(), etc. **Une fois que vous avez implémenté votre modèle, vous devez le comparer avec un modèle construit en utilisant les capacités de pytorch qui permettent une différenciation automatique. Autrement dit, pour la deuxième implémentation, vous pouvez utilisertorch.nn, torch.autograd ou à la méthode .backward().** Vous pouvez utiliser l’implémentation de votre choix pour explorer différentes architectures de modèles."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Votre pseudocode:"
      ],
      "metadata": {
        "id": "F1mpuG2cwER-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Algorithme de rétropopagation dans un réseau de neurones pour un exemple $\\tilde{x}_i$:\n",
        "\n",
        "1. TODO\n",
        "2. TODO\n",
        "3. TODO..."
      ],
      "metadata": {
        "id": "qY2X9goYwMDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fonctions à compléter"
      ],
      "metadata": {
        "id": "SIQJD-TRwEdo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzIQ0S4qDPKJ"
      },
      "source": [
        "''' Les fonctions dans cette cellule peuvent avoir les mêmes déclarations que celles de la partie 2'''\n",
        "def accuracy(y, y_pred) :\n",
        "    # todo : nombre d'éléments à classifier.\n",
        "    card_D = None\n",
        "\n",
        "    # todo : calcul du nombre d'éléments bien classifiés.\n",
        "    card_C = None\n",
        "    +\n",
        "    # todo : calcul de la précision de classification.\n",
        "    acc = None\n",
        "\n",
        "    return acc, (card_C, card_D)\n",
        "\n",
        "def accuracy_and_loss_whole_dataset(data_loader, model):\n",
        "    cardinal = 0\n",
        "    loss     = 0.\n",
        "    n_accurate_preds  = 0.\n",
        "\n",
        "    for x, y in data_loader:\n",
        "        x, y = reshape_input(x, y)\n",
        "        y_pred                = model.forward(x)\n",
        "        xentrp                = cross_entropy(y, y_pred)\n",
        "        _, (n_acc, n_samples) = accuracy(y, y_pred)\n",
        "\n",
        "        cardinal = cardinal + n_samples\n",
        "        loss     = loss + xentrp\n",
        "        n_accurate_preds  = n_accurate_preds + n_acc\n",
        "\n",
        "    loss = loss / float(cardinal)\n",
        "    acc  = n_accurate_preds / float(cardinal)\n",
        "\n",
        "    return acc, loss\n",
        "\n",
        "def inputs_tilde(x, axis=-1):\n",
        "    # augments the inputs `x` with ones along `axis`\n",
        "    # todo : implémenter code ici.\n",
        "    x_tilde = None\n",
        "    return x_tilde\n",
        "\n",
        "def softmax(x, axis=-1):\n",
        "    # assurez vous que la fonction est numeriquement stable\n",
        "    # e.g. softmax(np.array([1000, 10000, 100000], ndim=2))\n",
        "\n",
        "    # todo : calcul des valeurs de softmax(x)\n",
        "    values = None\n",
        "    return values\n",
        "\n",
        "def cross_entropy(y, y_pred):\n",
        "    # todo : calcul de la valeur d'entropie croisée.\n",
        "    loss = None\n",
        "    return loss\n",
        "\n",
        " def softmax_cross_entropy_backward(y, y_pred):\n",
        "     # todo : calcul de la valeur du gradient de l'entropie croisée composée avec `softmax`\n",
        "     values = None\n",
        "     return values\n",
        "\n",
        "def relu_forward(x):\n",
        "    # todo : calcul des valeurs de relu(x)\n",
        "    values = None\n",
        "    return values\n",
        "\n",
        "def relu_backward(x):\n",
        "    # todo : calcul des valeurs du gradient de la fonction `relu`\n",
        "    values = None\n",
        "    return values\n",
        "\n",
        "\n",
        "# Model est une classe representant votre reseaux de neuronnes\n",
        "class MLPModel:\n",
        "    def __init__(self, n_features, n_hidden_features, n_hidden_layers, n_classes):\n",
        "        self.n_features        = n_features\n",
        "        self.n_hidden_features = n_hidden_features\n",
        "        self.n_hidden_layers   = n_hidden_layers\n",
        "        self.n_classes         = n_classes\n",
        "\n",
        "        # todo : initialiser la liste des paramètres Teta de l'estimateur.\n",
        "        self.params = None\n",
        "        print(f\"Teta params={[p.shape for p in self.params]}\")\n",
        "\n",
        "        self.a = None # liste contenant le resultat des multiplications matricielles\n",
        "        self.h = None # liste contenant le resultat des fonctions d'activations\n",
        "\n",
        "        self.t = 0\n",
        "        self.m_t = 0 # pour Adam: moyennes mobiles du gradient\n",
        "        self.v_t = 0 # pour Adam: moyennes mobiles du carré du gradient\n",
        "\n",
        "    def forward(self, x):\n",
        "        # todo : implémenter calcul des outputs en fonction des inputs `x`.\n",
        "        outputs = None\n",
        "        return outputs\n",
        "\n",
        "    def backward(self, y, y_pred):\n",
        "        # todo : implémenter calcul des gradients.\n",
        "        grads = None\n",
        "        return grads\n",
        "\n",
        "    def sgd_update(self, lr, grads):\n",
        "        pass # TODO : implémenter mise à jour des paramètres ici.\n",
        "\n",
        "    def adam_update(self, lr, grads):\n",
        "        # TODO : implémenter mise à jour des paramètres ici.\n",
        "        pass\n",
        "\n",
        "def train(model, lr=0.1, nb_epochs=10, sgd=True, data_loader_train=None, data_loader_val=None):\n",
        "    best_model = None\n",
        "    best_val_accuracy = 0\n",
        "    logger = Logger()\n",
        "\n",
        "    for epoch in range(nb_epochs+1):\n",
        "\n",
        "        # at epoch 0 evaluate random initial model\n",
        "        #   then for subsequent epochs, do optimize before evaluation.\n",
        "        if epoch > 0:\n",
        "            for x, y in data_loader_train:\n",
        "                x, y = reshape_input(x, y)\n",
        "\n",
        "                y_pred = model.forward(x)\n",
        "                grads  = model.backward(y, y_pred)\n",
        "                if sgd:\n",
        "                  model.sgd_update(lr, grads)\n",
        "                else:\n",
        "                  model.adam_update(lr, grads)\n",
        "\n",
        "        accuracy_train, loss_train = accuracy_and_loss_whole_dataset(data_loader_train, model)\n",
        "        accuracy_val, loss_val = accuracy_and_loss_whole_dataset(data_loader_val, model)\n",
        "\n",
        "        if accuracy_val > best_val_accuracy:\n",
        "          pass   # TODO : record the best model parameters and best validation accuracy\n",
        "\n",
        "        logger.log(accuracy_train, loss_train, accuracy_val, loss_val)\n",
        "        print(f\"Epoch {epoch:2d}, \\\n",
        "                Train:loss={loss_train.item():.3f}, accuracy={accuracy_train.item()*100:.1f}%, \\\n",
        "                Valid: loss={loss_val.item():.3f}, accuracy={accuracy_val.item()*100:.1f}%\", flush=True)\n",
        "\n",
        "    return best_model, best_val_accuracy, logger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Évaluation"
      ],
      "metadata": {
        "id": "tIe9DFvPwuQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD: Recherche d'hyperparamètres"
      ],
      "metadata": {
        "id": "ml5jUvG9AUXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD\n",
        "# Montrez les résultats pour différents nombre de couche, e.g. 1, 3, 5, et différent nombres de neurone, e.g. 25, 100, 300, 500, 1000.\n",
        "depth_list = None   # Define ranges in a list\n",
        "width_list = None   # Define ranges in a list\n",
        "lr = None           # Some value\n",
        "batch_size = None   # Some value\n",
        "\n",
        "with torch.no_grad():\n",
        "  for depth in depth_list:\n",
        "    for width in width_list:\n",
        "      print(\"------------------------------------------------------------------\")\n",
        "      print(\"Training model with a depth of {0} layers and a width of {1} units\".format(depth, width))\n",
        "      data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "      MLP_model = MLPModel(n_features=784, n_hidden_features=width, n_hidden_layers=depth, n_classes=10)\n",
        "      _, val_accuracy, _ = train(MLP_model,lr=lr, nb_epochs=5, sgd=True, data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "      print(f\"validation accuracy = {val_accuracy*100:.3f}\")"
      ],
      "metadata": {
        "id": "fe7hyN63AUXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Tableau pour la précision sur l'ensemble de validation**\n",
        "N.B. que les lignes correspondent aux nombre de couche et les colonnes correspondent au nombre de neurone dans chaque couche. Les valeurs ci-dessous sont donné comme exemples; remplacez-les par les valeurs que vous avez utilisées pour votre recherche d'hyperparamètres.\n",
        "\n",
        "depth\\width  | 25 | 100 | 300 | 500 | 1000\n",
        "-------------------|------------------|------------------|------------------|------------------|------------------|\n",
        "**1**   | -  | - | - | - | - |\n",
        "**3** | -  | - | - | - | - |\n",
        "**5**  | -  | - | - | - | - |"
      ],
      "metadata": {
        "id": "QnDMqFapAUXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD: Analyse du meilleur modèle"
      ],
      "metadata": {
        "id": "2wuN-uw7AUXN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CShZ3VB0AUXN"
      },
      "source": [
        "# SGD\n",
        "# Montrez les résultats pour la meilleure configuration trouvez ci-dessus.\n",
        "depth = None    # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "width = None    # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "lr = None           # Some value\n",
        "batch_size = None   # Some value\n",
        "\n",
        "with torch.no_grad():\n",
        "  data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "  MLP_model = MLPModel(n_features=784, n_hidden_features=width, n_hidden_layers=depth, n_classes=10)\n",
        "  best_model, best_val_accuracy, logger = train(MLP_model,lr=lr, nb_epochs=5, sgd=True,\n",
        "                                                data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "  logger.plot_loss_and_accuracy()\n",
        "  print(f\"Best validation accuracy = {best_val_accuracy*100:.3f}\")\n",
        "\n",
        "  accuracy_test, loss_test = accuracy_and_loss_whole_dataset(data_loader_test, best_model)\n",
        "print(\"Evaluation of the best training model over test set\")\n",
        "print(\"------\")\n",
        "print(f\"Loss : {loss_test:.3f}\")\n",
        "print(f\"Accuracy : {accuracy_test*100.:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adam: Recherche d'hyperparamètres\n",
        "\n",
        "Implémentez Adam, répétez les deux étapes précédentes (recherche d'hyperparamètres et analyse du meilleur modèle) cette fois en utilisat Adam, et comparez les performances finales avec votre meilleur modèle SGD."
      ],
      "metadata": {
        "id": "_tPLgZriAUXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM\n",
        "# Montrez les résultats pour différents nombre de couche, e.g. 1, 3, 5, et différent nombres de neurone, e.g. 25, 100, 300, 500, 1000.\n",
        "depth_list = None   # Define ranges in a list\n",
        "width_list = None   # Define ranges in a list\n",
        "lr = None           # Some value\n",
        "batch_size = None   # Some value\n",
        "\n",
        "with torch.no_grad():\n",
        "  for depth in depth_list:\n",
        "    for width in width_list:\n",
        "      print(\"------------------------------------------------------------------\")\n",
        "      print(\"Training model with a depth of {0} layers and a width of {1} units\".format(depth, width))\n",
        "      data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "      MLP_model = MLPModel(n_features=784, n_hidden_features=width, n_hidden_layers=depth, n_classes=10)\n",
        "      _, val_accuracy, _ = train(MLP_model, lr=lr, nb_epochs=5, sgd=False, data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "      print(f\"validation accuracy = {val_accuracy*100:.3f}\")"
      ],
      "metadata": {
        "id": "tEVOh1r7AUXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Tableau pour la précision sur l'ensemble de validation**\n",
        "N.B. que les lignes correspondent aux nombre de couche et les colonnes correspondent au nombre de neurone dans chaque couche. Les valeurs ci-dessous sont donné comme exemples; remplacez-les par les valeurs que vous avez utilisées pour votre recherche d'hyperparamètres.\n",
        "\n",
        "depth\\width  | 25 | 100 | 300 | 500 | 1000\n",
        "-------------------|------------------|------------------|------------------|------------------|------------------|\n",
        "**1**   | -  | - | - | - | - |\n",
        "**3** | -  | - | - | - | - |\n",
        "**5**  | -  | - | - | - | - |"
      ],
      "metadata": {
        "id": "6LQ6q18CAUXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adam: Analyse du meilleur modèle"
      ],
      "metadata": {
        "id": "df6Y9ziXAUXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM\n",
        "# Montrez les résultats pour la meilleure configuration trouvez ci-dessus.\n",
        "depth = None    # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "width = None    # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
        "lr = None           # Some value\n",
        "batch_size = None   # Some value\n",
        "\n",
        "with torch.no_grad():\n",
        "  data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
        "\n",
        "  MLP_model = MLPModel(n_features=784, n_hidden_features=width, n_hidden_layers=depth, n_classes=10)\n",
        "  best_model, best_val_accuracy, logger = train(MLP_model,lr=lr, nb_epochs=5, sgd=False,\n",
        "                                                data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
        "  logger.plot_loss_and_accuracy()\n",
        "  print(f\"Best validation accuracy = {best_val_accuracy*100:.3f}\")\n",
        "\n",
        "  accuracy_test, loss_test = accuracy_and_loss_whole_dataset(data_loader_test, best_model)\n",
        "print(\"Evaluation of the best training model over test set\")\n",
        "print(\"------\")\n",
        "print(f\"Loss : {loss_test:.3f}\")\n",
        "print(f\"Accuracy : {accuracy_test*100.:.3f}\")"
      ],
      "metadata": {
        "id": "uohnWTtoAUXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyse des Résultats"
      ],
      "metadata": {
        "id": "-wlDcZB-AUXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Répondez içi..."
      ],
      "metadata": {
        "id": "M-Wi3CG3AUXP"
      }
    }
  ]
}